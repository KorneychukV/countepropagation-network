{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import random\n",
    "import math\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "temp_mse_values = []\n",
    "mse_values = []\n",
    "all_mse_values = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Считывание данных из файла и их подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBdate(bdate):\n",
    "  return datetime.strptime(bdate, '%d.%m.%Y').month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Студенты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop_column = ['№п/п', 'Основание поступления']\n",
    "# gender_dict = {'Мужской': 1,'Женский': 0}\n",
    "\n",
    "# # подготовленный датасет\n",
    "# train_data = []\n",
    "\n",
    "# # датасет для тестирования\n",
    "# test_data = []\n",
    "\n",
    "# df = pd.read_csv('data/input.csv', sep=',')\n",
    "# df.drop(drop_column, axis = 1, inplace = True)\n",
    "\n",
    "# # переводим пол в числовой формат, т. к. это будет один из признаков\n",
    "# df['Пол'].replace(gender_dict, inplace = True) \n",
    "\n",
    "# # приводим баллы по ЕГЭ к диапозону от 0 до 1\n",
    "# df.astype({'Баллы ЕГЭ': 'float'}).dtypes\n",
    "# df['Баллы ЕГЭ'] /= 100\n",
    "    \n",
    "# fios = df['ФИО'].unique()\n",
    "# subjects = df['Предметы ЕГЭ'].unique()\n",
    "# cities = df['Населенный пункт по прописке'].unique()\n",
    "# schools = df['Учебное заведение'].unique()\n",
    "# classes = df['Специальность/направление'].unique()\n",
    "\n",
    "# # # количество признаков входного слоя\n",
    "# feature_count = len(subjects) + 1\n",
    "\n",
    "# for el in fios:\n",
    "#     student = df[df['ФИО'] == el]\n",
    "#     features = np.zeros((feature_count))\n",
    "#     for i in range(len(subjects)):\n",
    "#         res = student.loc[student['Предметы ЕГЭ'] == subjects[i], 'Баллы ЕГЭ'].values\n",
    "#         features[i] = res[0] if len(res) else 0\n",
    "    \n",
    "#     features[len(subjects)] = student.iloc[0]['Пол']\n",
    "    \n",
    "# #     features[6] = getBdate(student.iloc[0]['Дата рождения']) / 12\n",
    "    \n",
    "# #     city_index = np.where(cities == student.iloc[0]['Населенный пункт по прописке'])[0]\n",
    "# #     features[7] = 0 if len(city_index) == 0 else city_index[0]/len(cities)\n",
    "    \n",
    "# #     school_number = np.where(schools == student.iloc[0]['Учебное заведение'])[0]\n",
    "# #     features[8] = 0 if len(school_number) == 0 else school_number[0]/len(schools)\n",
    "    \n",
    "#     # Нормализация входного вектора\n",
    "# #     norm_features = np.zeros((feature_count))\n",
    "# #     for i in range(len(features)):\n",
    "# #         sum = 0 \n",
    "# #         for j in range(len(features)):\n",
    "# #             sum += features[j] ** 2\n",
    "# #         norm_features[i] = features[i] / math.sqrt(sum)\n",
    "# #     norm_features = (features * features.mean()) / features.std()\n",
    "    \n",
    "#     res = np.zeros((len(classes)))\n",
    "#     res[np.where(classes == student.iloc[0]['Специальность/направление'])[0].item(0)] = 1\n",
    "    \n",
    "    \n",
    "    \n",
    "#     # Нормализованные\n",
    "# #     temp_data = dict(fio = el, features = norm_features, result = res)\n",
    "#     # Не нормализованные\n",
    "#     temp_data = dict(fio = el, features = features, result = res)\n",
    "    \n",
    "#     # 90% - train, 10% - test\n",
    "#     if (len(train_data) / len(fios)) < 0.9:\n",
    "#         train_data.append(temp_data)\n",
    "#     else:\n",
    "#         test_data.append(temp_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Студенты (информатика)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # подготовленный датасет\n",
    "# train_data = []\n",
    "# # датасет для тестирования\n",
    "# test_data = []\n",
    "\n",
    "# drop_column = ['№п/п', 'Основание поступления']\n",
    "# gender_dict = {'Мужской': 1,'Женский': 0}\n",
    "\n",
    "# df = pd.read_csv('data/input.csv', sep=',')\n",
    "# df.drop(drop_column, axis = 1, inplace = True)\n",
    "\n",
    "# # переводим пол в числовой формат, т. к. это будет один из признаков\n",
    "# df['Пол'].replace(gender_dict, inplace = True) \n",
    "\n",
    "# # приводим баллы по ЕГЭ к диапозону от 0 до 1\n",
    "# df.astype({'Баллы ЕГЭ': 'float'}).dtypes\n",
    "# df['Баллы ЕГЭ'] /= 100\n",
    "\n",
    "# # Смотрим только для информатики\n",
    "# fios = df.loc[df['Предметы ЕГЭ'] == 'Информатика и ИКТ', 'ФИО']\n",
    "# classes = df.loc[df['Предметы ЕГЭ'] == 'Информатика и ИКТ', 'Специальность/направление'].unique()\n",
    "# subjects = df.loc[df['Специальность/направление'].isin(classes), 'Предметы ЕГЭ'].unique()\n",
    "\n",
    "# # количество признаков входного слоя\n",
    "# feature_count = len(subjects) + 1\n",
    "\n",
    "# for el in fios:\n",
    "#     student = df[df['ФИО'] == el]\n",
    "#     features = np.zeros((feature_count))\n",
    "#     for i in range(len(subjects)):\n",
    "#         res = student.loc[student['Предметы ЕГЭ'] == subjects[i], 'Баллы ЕГЭ'].values\n",
    "#         features[i] = res[0] if len(res) else 0\n",
    "#     features[len(subjects)] = student.iloc[0]['Пол']\n",
    "    \n",
    "#     # Нормализация входного вектора\n",
    "#     norm_features = np.zeros((feature_count))\n",
    "#     for i in range(len(features)):\n",
    "#         sum = 0 \n",
    "#         for j in range(len(features)):\n",
    "#             sum += features[j] ** 2\n",
    "#         norm_features[i] = features[i] / math.sqrt(sum)\n",
    "    \n",
    "#     res = np.zeros((len(classes)))\n",
    "#     res[np.where(classes == student.iloc[0]['Специальность/направление'])[0][0]] = 1\n",
    "    \n",
    "#     # Нормализованные\n",
    "#     temp_data = dict(fio = el, features = norm_features, result = res)\n",
    "#     # Не нормализованные\n",
    "# #     temp_data = dict(fio = el, features = features, result = res)\n",
    "    \n",
    "#     # 90% - train, 10% - test\n",
    "#     if (len(train_data) / len(fios)) < 0.9:\n",
    "#         train_data.append(temp_data)\n",
    "#     else:\n",
    "#         test_data.append(temp_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ирис"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# количество признаков входного слоя\n",
    "feature_count = 4\n",
    "\n",
    "df = pd.read_csv('data/iris.csv', sep=',')\n",
    "\n",
    "# подготовленный датасет\n",
    "train_data = []\n",
    "# датасет для тестирования\n",
    "test_data = []\n",
    "\n",
    "classes = df[\"variety\"].unique()\n",
    "\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "for i in range(len(df)) : \n",
    "\n",
    "    features = np.zeros((feature_count))\n",
    "    features[0] = df.loc[i, \"sepal.length\"]\n",
    "    features[1] = df.loc[i, \"sepal.width\"]\n",
    "    features[2] = df.loc[i, \"petal.length\"]\n",
    "    features[3] = df.loc[i, \"petal.width\"]\n",
    "    \n",
    "    # Нормализация входного вектора\n",
    "    norm_features = features/np.linalg.norm(features)\n",
    "    \n",
    "    res = np.zeros((len(classes)))\n",
    "    res[np.where(classes == df.loc[i, \"variety\"])[0].item(0)] = 1\n",
    "    \n",
    "    temp_data = dict(name = str(i), \n",
    "                     features = norm_features, \n",
    "                     result = res)\n",
    "    \n",
    "    if (len(train_data) / len(df)) < 0.9:\n",
    "        train_data.append(temp_data)\n",
    "#         test_data.append(temp_data)\n",
    "    else:\n",
    "#         train_data.append(temp_data)\n",
    "        test_data.append(temp_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Кохонен"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Методы для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getKohonenWinnerIndex(x, neuron_counts, w, s):\n",
    "    result = 0\n",
    "    max_net = -1\n",
    "    for i in range(neuron_counts):\n",
    "        net = 0\n",
    "        for j in range(len(x)):\n",
    "            net += x[j] * w[j][i] * s[i]\n",
    "        if (net > max_net):\n",
    "            result = i\n",
    "            max_net = net\n",
    "    return result\n",
    "\n",
    "def getKohonenNormResult(x, neuron_counts, w):\n",
    "    result = np.zeros((neuron_counts))\n",
    "    max_index = 0\n",
    "    max_net = -1\n",
    "    \n",
    "    for i in range(neuron_counts):\n",
    "        net = 0\n",
    "        for j in range(len(x)):\n",
    "            net += (x[j]+0.001) * w[j][i]\n",
    "        if (net > max_net):\n",
    "            max_index = i\n",
    "            max_net = net\n",
    "        result[i] = net\n",
    "    \n",
    "    summ = 0\n",
    "    for i in range(neuron_counts):\n",
    "        if i != max_index:\n",
    "            summ += result[i] ** 2\n",
    "    divider = math.sqrt(summ)\n",
    "    \n",
    "    for i in range(neuron_counts):    \n",
    "        if i != max_index:\n",
    "            result[i] /= divider\n",
    "    \n",
    "    result[max_index] = 1\n",
    "    return result\n",
    "\n",
    "def getNeuronNet(x, w):\n",
    "    result = 0\n",
    "    for i in range(len(x)):\n",
    "        result += x[i] * w[i]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Инициализация параметров обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# скорость обучения слоя Кохонена\n",
    "# лучший результат для студентов theta = 0.7\n",
    "# лучший результат для студентов (информатика) theta = 0.7\n",
    "# лучший результат для ирисок theta = 0.7\n",
    "theta = 0.7\n",
    "# лучший результат для студентов kohonen_neuron_count = 15\n",
    "# лучший результат для студентов (информатика) kohonen_neuron_count = 30\n",
    "# лучший результат для ирисок kohonen_neuron_count = 15\n",
    "kohonen_neuron_count = 15\n",
    "# штрафы кластеров\n",
    "s_w = np.ones((kohonen_neuron_count))\n",
    "# количество эпох\n",
    "# лучший результат для студентов epoch_count = 10\n",
    "# лучший результат для студентов (информатика) epoch_count = 100\n",
    "# лучший результат для ирисок epoch_count = 20\n",
    "epoch_count = 20\n",
    "\n",
    "#инициализация начальных весов слоя Кохонена kohonen_w[x][y]\n",
    "# x - индекс нейрона входного слоя\n",
    "# y - индекс нейрона слоя Кохонена\n",
    "kohonen_w = np.random.uniform(-1, 1, (feature_count, kohonen_neuron_count))\n",
    "\n",
    "# Коэффициент изменение скорости обучения\n",
    "# 0.1 для студентов\n",
    "# 0.0003 для студентов (информатика)\n",
    "# 0.0003 для ирисок\n",
    "thetaSpeed = 0.0003\n",
    "\n",
    "# Штраф за победу нейрона\n",
    "# 0.9 для студентов\n",
    "# 0.995 для студентов (информатика)\n",
    "# 0.995 для ирисок\n",
    "fine = 0.995"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение слоя Кохонена"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = epoch_count * len(train_data)\n",
    "# Обучение на подготовленном датасете\n",
    "while step >= 0:\n",
    "    \n",
    "    student = train_data[random.randint(0, len(train_data) - 1)]\n",
    "    \n",
    "    # Определение нейрона победителя\n",
    "    winner_index = getKohonenWinnerIndex(student['features'], kohonen_neuron_count, kohonen_w, s_w)\n",
    "    # Увеличиваем штраф, уменьшая его коэффициент\n",
    "    s_w[winner_index] *= fine\n",
    "    # Корректировка весов нейрона победителя на слое Кохонена\n",
    "    for i in range(feature_count):\n",
    "        kohonen_w[i][winner_index] += theta * (student['features'][i] - kohonen_w[i][winner_index])\n",
    "    # Изменение скорости обучения\n",
    "    theta -= (theta * thetaSpeed)\n",
    "    step -= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Перцептрон"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Методы для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(net):\n",
    "    return 1.0/(1 + np.exp(-net))\n",
    "\n",
    "def logistic_deriv(x):\n",
    "    return activation(x) * (1 - activation(x))\n",
    "\n",
    "def mse(pred, actual):\n",
    "    return np.square(np.subtract(actual,pred)).mean()\n",
    "\n",
    "def mse_deriv(pred, actual):\n",
    "    return -(2/len(pred)) * np.subtract(actual,pred).sum()\n",
    "\n",
    "def mse_deriv_private(pred, actual):\n",
    "    return -2 * (actual - pred)\n",
    "\n",
    "def get_vector_length(vector):\n",
    "    return math.sqrt(np.square(vector).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Инициализация параметров обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение перцептрона\n",
    "# 30 для студентов\n",
    "# 30 для студентов (информатика)\n",
    "# 20 для ирисок\n",
    "epoch_count = 20\n",
    "\n",
    "# Количество нейронов вхоного слоя\n",
    "per_input_neuron_count = kohonen_neuron_count\n",
    "# per_input_neuron_count = len(train_data[0]['features'])\n",
    "\n",
    "# количество скрытых слоев\n",
    "# 1 для студентов\n",
    "# 1 для студентов (информатика)\n",
    "# 1 для ирисок\n",
    "hiden_layer_count = 1\n",
    "\n",
    "# Количество нейронов выходного слоя\n",
    "output_neuron_count = len(train_data[0]['result'])\n",
    "\n",
    "# количество нейронов в слоях, последний слой выходной, первый - входной\n",
    "# 25 для студентов\n",
    "# 25 для студентов (информатика)\n",
    "# 25 для ирисок\n",
    "neuron_count = [per_input_neuron_count, 25, output_neuron_count]\n",
    "\n",
    "# Максимальное количество нейронов на каком-либо слое\n",
    "max_neuron_count = np.max(neuron_count)\n",
    "\n",
    "# Количество слоем\n",
    "layers_count = len(neuron_count)\n",
    "\n",
    "# скорость обучения\n",
    "# 0.7 для студентов\n",
    "# 0.4 для студентов (информатика)\n",
    "# 0.4 для ирисок\n",
    "beta = 0.4\n",
    "\n",
    "# Кэффициент изменение скорости обучения\n",
    "# для студентов betaSpeed = 0.0009\n",
    "# для студентов (информатика)  betaSpeed = 0.0005\n",
    "# для ирисок betaSpeed = 0.0009\n",
    "betaSpeed = 0.0009"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение перцептрона"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "MSE mean: 0.2184087642821229\n",
      "beta: 0.39964\n",
      "Epoch 1\n",
      "MSE mean: 0.1546391942230037\n",
      "beta: 0.399280324\n",
      "Epoch 2\n",
      "MSE mean: 0.12398019015691188\n",
      "beta: 0.3989209717084\n",
      "Epoch 3\n",
      "MSE mean: 0.10793541282871595\n",
      "beta: 0.3985619428338625\n",
      "Epoch 4\n",
      "MSE mean: 0.09785196606884271\n",
      "beta: 0.398203237085312\n",
      "Epoch 5\n",
      "MSE mean: 0.09089954119339888\n",
      "beta: 0.39784485417193527\n",
      "Epoch 6\n",
      "MSE mean: 0.08591706749097243\n",
      "beta: 0.3974867938031805\n",
      "Epoch 7\n",
      "MSE mean: 0.08226018204537267\n",
      "beta: 0.39712905568875767\n",
      "Epoch 8\n",
      "MSE mean: 0.07951117022986959\n",
      "beta: 0.3967716395386378\n",
      "Epoch 9\n",
      "MSE mean: 0.07739356208032867\n",
      "beta: 0.396414545063053\n",
      "Epoch 10\n",
      "MSE mean: 0.0757252943299087\n",
      "beta: 0.39605777197249625\n",
      "Epoch 11\n",
      "MSE mean: 0.07438555463037377\n",
      "beta: 0.395701319977721\n",
      "Epoch 12\n",
      "MSE mean: 0.07329255085811494\n",
      "beta: 0.39534518878974106\n",
      "Epoch 13\n",
      "MSE mean: 0.07238944987903927\n",
      "beta: 0.3949893781198303\n",
      "Epoch 14\n",
      "MSE mean: 0.07163566783559851\n",
      "beta: 0.39463388767952245\n",
      "Epoch 15\n",
      "MSE mean: 0.07100145301275693\n",
      "beta: 0.39427871718061086\n",
      "Epoch 16\n",
      "MSE mean: 0.07046445915116606\n",
      "beta: 0.3939238663351483\n",
      "Epoch 17\n",
      "MSE mean: 0.07000752939979567\n",
      "beta: 0.39356933485544665\n",
      "Epoch 18\n",
      "MSE mean: 0.06961722959111345\n",
      "beta: 0.39321512245407675\n",
      "Epoch 19\n",
      "MSE mean: 0.06928285555851828\n",
      "beta: 0.3928612288438681\n",
      "Epoch 20\n",
      "MSE mean: 0.0689957471315375\n",
      "beta: 0.39250765373790863\n",
      "Epoch 21\n",
      "MSE mean: 0.06874880473742724\n",
      "beta: 0.3921543968495445\n",
      "Epoch 22\n",
      "MSE mean: 0.06853614240354199\n",
      "beta: 0.3918014578923799\n",
      "Epoch 23\n",
      "MSE mean: 0.06835283414430522\n",
      "beta: 0.3914488365802768\n",
      "Epoch 24\n",
      "MSE mean: 0.06819472525961008\n",
      "beta: 0.39109653262735455\n",
      "Epoch 25\n",
      "MSE mean: 0.06805828939772518\n",
      "beta: 0.39074454574798995\n",
      "Epoch 26\n",
      "MSE mean: 0.06794051833639532\n",
      "beta: 0.39039287565681674\n",
      "Epoch 27\n",
      "MSE mean: 0.06783883549399396\n",
      "beta: 0.3900415220687256\n",
      "Epoch 28\n",
      "MSE mean: 0.0677510269186794\n",
      "beta: 0.38969048469886375\n",
      "Epoch 29\n",
      "MSE mean: 0.06767518536707173\n",
      "beta: 0.38933976326263475\n",
      "Epoch 30\n",
      "MSE mean: 0.06760966436243089\n",
      "beta: 0.3889893574756984\n",
      "Epoch 31\n",
      "MSE mean: 0.0675530400037398\n",
      "beta: 0.3886392670539703\n",
      "Epoch 32\n",
      "MSE mean: 0.06750407890704255\n",
      "beta: 0.3882894917136217\n",
      "Epoch 33\n",
      "MSE mean: 0.06746171108402763\n",
      "beta: 0.38794003117107945\n",
      "Epoch 34\n",
      "MSE mean: 0.06742500685857733\n",
      "beta: 0.3875908851430255\n",
      "Epoch 35\n",
      "MSE mean: 0.0673931571300616\n",
      "beta: 0.3872420533463968\n",
      "Epoch 36\n",
      "MSE mean: 0.06736545644026092\n",
      "beta: 0.386893535498385\n",
      "Epoch 37\n",
      "MSE mean: 0.06734128840798628\n",
      "beta: 0.3865453313164365\n",
      "Epoch 38\n",
      "MSE mean: 0.0673201131746949\n",
      "beta: 0.38619744051825167\n",
      "Epoch 39\n",
      "MSE mean: 0.067301456564449\n",
      "beta: 0.38584986282178524\n",
      "Epoch 40\n",
      "MSE mean: 0.06728490070831765\n",
      "beta: 0.3855025979452456\n",
      "Epoch 41\n",
      "MSE mean: 0.06727007592070314\n",
      "beta: 0.38515564560709487\n",
      "Epoch 42\n",
      "MSE mean: 0.06725665364569912\n",
      "beta: 0.38480900552604846\n",
      "Epoch 43\n",
      "MSE mean: 0.06724434031721198\n",
      "beta: 0.38446267742107504\n",
      "Epoch 44\n",
      "MSE mean: 0.06723287199839666\n",
      "beta: 0.3841166610113961\n",
      "Epoch 45\n",
      "MSE mean: 0.0672220096848222\n",
      "beta: 0.3837709560164858\n",
      "Epoch 46\n",
      "MSE mean: 0.06721153517232725\n",
      "beta: 0.383425562156071\n",
      "Epoch 47\n",
      "MSE mean: 0.0672012474052655\n",
      "beta: 0.38308047915013055\n",
      "Epoch 48\n",
      "MSE mean: 0.06719095923422536\n",
      "beta: 0.38273570671889545\n",
      "Epoch 49\n",
      "MSE mean: 0.06718049452476761\n",
      "beta: 0.38239124458284846\n",
      "Epoch 50\n",
      "MSE mean: 0.0671696855706862\n",
      "beta: 0.3820470924627239\n",
      "Epoch 51\n",
      "MSE mean: 0.06715837077720858\n",
      "beta: 0.38170325007950745\n",
      "Epoch 52\n",
      "MSE mean: 0.0671463925918786\n",
      "beta: 0.3813597171544359\n",
      "Epoch 53\n",
      "MSE mean: 0.0671335956740818\n",
      "beta: 0.3810164934089969\n",
      "Epoch 54\n",
      "MSE mean: 0.0671198253087365\n",
      "beta: 0.3806735785649288\n",
      "Epoch 55\n",
      "MSE mean: 0.0671049260859519\n",
      "beta: 0.38033097234422036\n",
      "Epoch 56\n",
      "MSE mean: 0.06708874088663054\n",
      "beta: 0.37998867446911055\n",
      "Epoch 57\n",
      "MSE mean: 0.0670711102338884\n",
      "beta: 0.37964668466208834\n",
      "Epoch 58\n",
      "MSE mean: 0.06705187209100587\n",
      "beta: 0.37930500264589245\n",
      "Epoch 59\n",
      "MSE mean: 0.06703086220671982\n",
      "beta: 0.37896362814351114\n",
      "Epoch 60\n",
      "MSE mean: 0.06700791512504876\n",
      "beta: 0.37862256087818197\n",
      "Epoch 61\n",
      "MSE mean: 0.06698286598492219\n",
      "beta: 0.3782818005733916\n",
      "Epoch 62\n",
      "MSE mean: 0.06695555322829189\n",
      "beta: 0.37794134695287557\n",
      "Epoch 63\n",
      "MSE mean: 0.06692582230626792\n",
      "beta: 0.37760119974061795\n",
      "Epoch 64\n",
      "MSE mean: 0.06689353041279986\n",
      "beta: 0.3772613586608514\n",
      "Epoch 65\n",
      "MSE mean: 0.0668585521778292\n",
      "beta: 0.37692182343805664\n",
      "Epoch 66\n",
      "MSE mean: 0.06682078611494423\n",
      "beta: 0.3765825937969624\n",
      "Epoch 67\n",
      "MSE mean: 0.06678016144968071\n",
      "beta: 0.3762436694625451\n",
      "Epoch 68\n",
      "MSE mean: 0.0667366447736721\n",
      "beta: 0.37590505016002884\n",
      "Epoch 69\n",
      "MSE mean: 0.06669024581043023\n",
      "beta: 0.3755667356148848\n",
      "Epoch 70\n",
      "MSE mean: 0.06664102148390404\n",
      "beta: 0.3752287255528314\n",
      "Epoch 71\n",
      "MSE mean: 0.06658907749402208\n",
      "beta: 0.37489101969983385\n",
      "Epoch 72\n",
      "MSE mean: 0.06653456675205963\n",
      "beta: 0.374553617782104\n",
      "Epoch 73\n",
      "MSE mean: 0.06647768431163152\n",
      "beta: 0.3742165195261001\n",
      "Epoch 74\n",
      "MSE mean: 0.06641865881154502\n",
      "beta: 0.3738797246585266\n",
      "Epoch 75\n",
      "MSE mean: 0.06635774085852501\n",
      "beta: 0.3735432329063339\n",
      "Epoch 76\n",
      "MSE mean: 0.06629518914414043\n",
      "beta: 0.3732070439967182\n",
      "Epoch 77\n",
      "MSE mean: 0.06623125534700124\n",
      "beta: 0.3728711576571212\n",
      "Epoch 78\n",
      "MSE mean: 0.06616616898482611\n",
      "beta: 0.37253557361522976\n",
      "Epoch 79\n",
      "MSE mean: 0.0661001233529093\n",
      "beta: 0.37220029159897605\n",
      "Epoch 80\n",
      "MSE mean: 0.06603326354410317\n",
      "beta: 0.371865311336537\n",
      "Epoch 81\n",
      "MSE mean: 0.06596567732981991\n",
      "beta: 0.3715306325563341\n",
      "Epoch 82\n",
      "MSE mean: 0.06589738942708186\n",
      "beta: 0.3711962549870334\n",
      "Epoch 83\n",
      "MSE mean: 0.06582835940726535\n",
      "beta: 0.3708621783575451\n",
      "Epoch 84\n",
      "MSE mean: 0.06575848323128683\n",
      "beta: 0.3705284023970233\n",
      "Epoch 85\n",
      "MSE mean: 0.06568759813292958\n",
      "beta: 0.37019492683486593\n",
      "Epoch 86\n",
      "MSE mean: 0.06561549032943591\n",
      "beta: 0.36986175140071453\n",
      "Epoch 87\n",
      "MSE mean: 0.06554190483598941\n",
      "beta: 0.3695288758244539\n",
      "Epoch 88\n",
      "MSE mean: 0.0654665565227386\n",
      "beta: 0.3691962998362119\n",
      "Epoch 89\n",
      "MSE mean: 0.06538914150183048\n",
      "beta: 0.3688640231663593\n",
      "Epoch 90\n",
      "MSE mean: 0.06530934797899955\n",
      "beta: 0.36853204554550956\n",
      "Epoch 91\n",
      "MSE mean: 0.06522686584414886\n",
      "beta: 0.3682003667045186\n",
      "Epoch 92\n",
      "MSE mean: 0.06514139448506079\n",
      "beta: 0.36786898637448456\n",
      "Epoch 93\n",
      "MSE mean: 0.06505264855245288\n",
      "beta: 0.36753790428674754\n",
      "Epoch 94\n",
      "MSE mean: 0.06496036164404403\n",
      "beta: 0.3672071201728895\n",
      "Epoch 95\n",
      "MSE mean: 0.06486428807672671\n",
      "beta: 0.3668766337647339\n",
      "Epoch 96\n",
      "MSE mean: 0.0647642030580309\n",
      "beta: 0.3665464447943456\n",
      "Epoch 97\n",
      "MSE mean: 0.06465990164380947\n",
      "beta: 0.3662165529940307\n",
      "Epoch 98\n",
      "MSE mean: 0.06455119688403622\n",
      "beta: 0.3658869580963361\n",
      "Epoch 99\n",
      "MSE mean: 0.06443791752668364\n",
      "beta: 0.36555765983404936\n"
     ]
    }
   ],
   "source": [
    "#инициализация начальных весов Перцептрона weights[l][x][y]\n",
    "# l - индекс слоя (слои считаются с первого скрытого слоя)\n",
    "# x - индекс нейрона от которого идёт вес\n",
    "# y - индекс нейрона к которому идёт вес\n",
    "weights = np.random.uniform(-1, 1, (layers_count - 1, max_neuron_count, max_neuron_count))\n",
    "new_weights = np.zeros((layers_count - 1, max_neuron_count, max_neuron_count))\n",
    "\n",
    "# до активации нейронов preActiv[x][y]. Начинает с первого скрытого слоя\n",
    "# x - индекс слоя (слои считаются с первого скрытого слоя)\n",
    "# y - индекс нейрона в слое\n",
    "preActiv = np.zeros((layers_count - 1, max_neuron_count))\n",
    "\n",
    "# после активациии нейронов postActiv[x][y]\n",
    "# x - индекс слоя (слои считаются с входного слоя)\n",
    "# y - индекс нейрона в слое\n",
    "postActiv = np.zeros((layers_count, max_neuron_count))\n",
    "\n",
    "# для вычисления производной postActivDeriv[x][y]\n",
    "# x - индекс слоя (слои считаются с входного слоя)\n",
    "# y - индекс нейрона в слое\n",
    "postActivDeriv = np.zeros((layers_count, max_neuron_count))\n",
    "\n",
    "# ошибка на нейроне\n",
    "# x - индекс слоя (слои считаются с входного слоя)\n",
    "# y - индекс нейрона в слое\n",
    "err = np.zeros((layers_count, np.max(neuron_count[1:len(neuron_count)])))\n",
    "\n",
    "for ep in range(epoch_count):\n",
    "    print('Epoch ' + str(ep))\n",
    "    for el in range(len(train_data)):\n",
    "    \n",
    "        # получаем нормализованный входной вектор со слоя Кохонена\n",
    "        student = train_data[el]\n",
    "        train_el = getKohonenNormResult(student['features'], kohonen_neuron_count, kohonen_w)\n",
    "\n",
    "#         # подаем на вход датасет\n",
    "#         student = train_data[el]\n",
    "#         student = train_data[random.randint(0, len(train_data) - 1)]\n",
    "#         train_el = student['features']\n",
    "    \n",
    "        # Подготовка входного вектора\n",
    "        for i in range(len(train_el)):\n",
    "            postActiv[0][i] = train_el[i]\n",
    "\n",
    "        # Прямое распространение\n",
    "        for l in range(layers_count - 1):\n",
    "            for n_c in range(neuron_count[l + 1]):\n",
    "                preActiv[l][n_c] = np.dot(postActiv[l][0:neuron_count[l]], weights[l][0:neuron_count[l],n_c])\n",
    "                postActiv[l+1][n_c] = activation(preActiv[l][n_c])\n",
    "                postActivDeriv[l+1][n_c] = logistic_deriv(preActiv[l][n_c])\n",
    "            \n",
    "                \n",
    "        # Общая ошибка сети\n",
    "        err_common = mse(postActiv[layers_count-1][0:len(student['result'])], student['result'])\n",
    "        \n",
    "        \n",
    "        # Вычисляем производную от функции ошибки на каждом нейроне выходного слоя\n",
    "        for n_c in range(neuron_count[layers_count - 1]):\n",
    "            err[layers_count - 2][n_c] = mse_deriv_private(postActiv[layers_count-1][n_c], student['result'][n_c])\n",
    "        \n",
    "        # Изменение последнего слоя весов (веса от последнего скрытого слоя к выходному слою)\n",
    "        # in_c - индекс нейрона входного слоя\n",
    "        # out_c - индекс нейрона выходного слоя\n",
    "        for in_c in range(neuron_count[layers_count - 2]):\n",
    "            # Производная от взвешенного значения приходящего на нейрон выходного слоя по вычисляемому весу\n",
    "            # т. е. значение нейрона последнего скрытого слоя после функции активации\n",
    "            c = postActiv[layers_count-2][in_c]\n",
    "            for out_c in range(neuron_count[layers_count - 1]):\n",
    "                # Значение производной от функции ошибки на нейроне выходного слоя\n",
    "                a = err[layers_count - 2][out_c]\n",
    "                # Значение производной от функции активации на нейроне выходного слоя\n",
    "                b = postActivDeriv[layers_count-1][out_c]\n",
    "                # Старое значение веса\n",
    "                w = weights[layers_count - 2][in_c, out_c]\n",
    "                new_weights[layers_count - 2][in_c, out_c] = w - beta * a * b * c\n",
    "        \n",
    "        if hiden_layer_count > 0:\n",
    "            # Индексы слоев в обратную сторону\n",
    "            for l in range(layers_count - 3, -1, -1):\n",
    "                # Индексы нейронов от которых идет вес\n",
    "                for in_c in range(neuron_count[l]):\n",
    "                    # ПОМЕНЯТЬ Производная от функции активации следующего слоя\n",
    "                    c = postActiv[l-1][in_c]\n",
    "                    # Индексы нейронов к которым идет вес\n",
    "                    for out_c in range(neuron_count[l + 1]):\n",
    "                        # Ошибка идущая на предыдущий слой\n",
    "                        for out_out_c in range(neuron_count[l + 2]):\n",
    "                            a1 = err[l + 2][out_out_c]\n",
    "                            a2 = postActivDeriv[l+2][out_out_c]\n",
    "                            a3 = weights[l+1][out_c][out_out_c]\n",
    "                            err[l+1][out_c] += a1 * a2 * a3\n",
    "                        a = err[l+1][out_c]\n",
    "                        # Производная от функции активации предыдущего слоя\n",
    "                        b = postActivDeriv[l+1][out_c]\n",
    "                        # Старое значение веса\n",
    "                        w = weights[l][in_c, out_c]\n",
    "                        new_weights[l][in_c, out_c] = w - beta * a * b * c\n",
    "        \n",
    "        weights = new_weights.copy()\n",
    "        temp_mse_values.append(err_common)\n",
    "        all_mse_values.append(err_common)\n",
    "    \n",
    "    # Изменение скорости обучения\n",
    "    beta -= (beta * betaSpeed)\n",
    "    \n",
    "    mse_values.append(np.array((temp_mse_values)).mean())\n",
    "    print('MSE mean: ' + str(np.array((temp_mse_values)).mean()))\n",
    "    print('beta: ' + str(beta))\n",
    "    temp_mse_values = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## График изменения среднеквадратической ошибки от поколения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(len(mse_values))\n",
    "plt.plot(mse_values)\n",
    "plt.ylabel('MSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тестирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование студентов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Тестирование перцептрона\n",
    "\n",
    "# # до активации нейронов preActiv[x][y]\n",
    "# # x - индекс слоя (слои считаются с первого скрытого слоя)\n",
    "# # y - индекс нейрона в слое\n",
    "# preActiv = np.zeros((len(neuron_count) - 1, max_neuron_count))\n",
    "# # после активациии нейронов postActiv[x][y]\n",
    "# # x - индекс слоя (слои считаются с входного слоя)\n",
    "# # y - индекс нейрона в слое\n",
    "# postActiv = np.zeros((len(neuron_count), max_neuron_count))\n",
    "    \n",
    "# y_pred = 0\n",
    "# y_real = len(test_data)\n",
    "# accuracy = 0\n",
    "# for el in range(len(test_data)):\n",
    "   \n",
    "#     # получаем нормализованный входной вектор со слоя Кохонена\n",
    "#     student = test_data[el]\n",
    "#     test_el = getKohonenNormResult(student['features'], kohonen_neuron_count, kohonen_w)    \n",
    "\n",
    "#     # подаем на вход интересующее значение\n",
    "# #     student = test_data[el]\n",
    "# #     test_el = student['features']\n",
    "\n",
    "#     for i in range(len(test_el)):\n",
    "#         postActiv[0][i] = test_el[i]\n",
    "\n",
    "#     # Проходим по всем слоям\n",
    "#     for l in range(len(neuron_count) - 1):\n",
    "#         for n_c in range(neuron_count[l + 1]):\n",
    "#             preActiv[l][n_c] = np.dot(postActiv[l][0:neuron_count[l]], weights[l][0:neuron_count[l],n_c])\n",
    "#             postActiv[l+1][n_c] = activation(preActiv[l][n_c])    \n",
    "\n",
    "#     print(student['fio'])\n",
    "#     print('Поступил на специальность: ' + classes[np.where(student['result'] == 1)[0][0]])\n",
    "#     print('Результаты нейросети:')\n",
    "#     result = postActiv[len(neuron_count)-1][0:len(student['result'])]\n",
    "    \n",
    "    \n",
    "#     best_results = [0.0, 0.0, 0.0]\n",
    "#     best_indexes = [0, 1, 2]\n",
    "#     max_res = 0.0\n",
    "#     max_index = 0\n",
    "#     for i in range(len(result)):\n",
    "# #         print(classes[i] + ' - ' + str(result[i] * 100) + '%')\n",
    "# #         print('-------------')\n",
    "#         if (result[i] > best_results[0]):\n",
    "#             best_results[2] = best_results[1]\n",
    "#             best_results[1] = best_results[0]\n",
    "#             best_results[0] = result[i]\n",
    "#             best_indexes[2] = best_indexes[1]\n",
    "#             best_indexes[1] = best_indexes[0]\n",
    "#             best_indexes[0] = i\n",
    "#         elif (result[i] > best_results[1]):\n",
    "#             best_results[2] = best_results[1]\n",
    "#             best_results[1] = result[i]\n",
    "#             best_indexes[2] = best_indexes[1]\n",
    "#             best_indexes[1] = i\n",
    "#         elif (result[i] > best_results[2]):\n",
    "#             best_results[2] = result[i]\n",
    "#             best_indexes[2] = i\n",
    "        \n",
    "#     print(classes[best_indexes[0]] + ': ' + str(result[best_indexes[0]] * 100) + '%')\n",
    "#     print(classes[best_indexes[1]] + ': ' + str(result[best_indexes[1]] * 100) + '%')\n",
    "#     print(classes[best_indexes[2]] + ': ' + str(result[best_indexes[2]] * 100) + '%')\n",
    "    \n",
    "#     if (np.where(student['result'] == 1)[0][0] in best_indexes):\n",
    "#         accuracy += 1\n",
    "        \n",
    "#     print()\n",
    "#     print('=================================================')\n",
    "#     print()\n",
    "\n",
    "# print('Точность: ' + str(accuracy / y_real * 100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование студентов (информатика)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Тестирование перцептрона\n",
    "\n",
    "# # до активации нейронов preActiv[x][y]\n",
    "# # x - индекс слоя (слои считаются с первого скрытого слоя)\n",
    "# # y - индекс нейрона в слое\n",
    "# preActiv = np.zeros((len(neuron_count) - 1, max_neuron_count))\n",
    "# # после активациии нейронов postActiv[x][y]\n",
    "# # x - индекс слоя (слои считаются с входного слоя)\n",
    "# # y - индекс нейрона в слое\n",
    "# postActiv = np.zeros((len(neuron_count), max_neuron_count))\n",
    "    \n",
    "# y_pred = 0\n",
    "# y_real = len(test_data)\n",
    "# accuracy = 0\n",
    "# for el in range(len(test_data)):\n",
    "   \n",
    "#     # получаем нормализованный входной вектор со слоя Кохонена\n",
    "#     student = test_data[el]\n",
    "#     test_el = getKohonenNormResult(student['features'], kohonen_neuron_count, kohonen_w)    \n",
    "\n",
    "#     for i in range(len(test_el)):\n",
    "#         postActiv[0][i] = test_el[i]\n",
    "\n",
    "#     # Проходим по всем слоям\n",
    "#     for l in range(len(neuron_count) - 1):\n",
    "#         for n_c in range(neuron_count[l + 1]):\n",
    "#             preActiv[l][n_c] = np.dot(postActiv[l][0:neuron_count[l]], weights[l][0:neuron_count[l],n_c])\n",
    "#             postActiv[l+1][n_c] = activation(preActiv[l][n_c])    \n",
    "\n",
    "#     print(student['fio'])\n",
    "#     print('Поступил на специальность: ' + classes[np.where(student['result'] == 1)[0][0]])\n",
    "#     print('Результаты нейросети:')\n",
    "#     result = postActiv[len(neuron_count)-1][0:len(student['result'])]\n",
    "    \n",
    "#     max_res = 0.0\n",
    "#     max_index = 0\n",
    "#     for i in range(len(result)):\n",
    "# #         print(classes[i] + ' - ' + str(result[i] * 100) + '%')\n",
    "# #         print('-------------')\n",
    "#         if (result[i] > max_res):\n",
    "#             max_index = i\n",
    "#             max_res = result[i]\n",
    "        \n",
    "#     print(classes[0] + ': ' + str(result[0] * 100) + '%')\n",
    "#     print(classes[1] + ': ' + str(result[1] * 100) + '%')\n",
    "#     print(classes[2] + ': ' + str(result[2] * 100) + '%')\n",
    "#     print('-------------------')\n",
    "#     print(classes[np.where(student['result'] == 1)[0][0]] + ': ' + str(result[np.where(student['result'] == 1)[0][0]] * 100) + '%')\n",
    "    \n",
    "#     if (np.where(student['result'] == 1)[0][0] == max_index):\n",
    "#         accuracy += 1\n",
    "        \n",
    "#     print()\n",
    "#     print('=================================================')\n",
    "#     print()\n",
    "\n",
    "# print('Точность: ' + str(accuracy / y_real * 100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование цветов Ириса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Индекс: 135\n",
      "Реальный вид: Virginica\n",
      "-----------------\n",
      "Результаты нейросети:\n",
      "Setosa: 1.0621831986361092%\n",
      "Versicolor: 17.06491279596324%\n",
      "Virginica: 83.73035579627442%\n",
      "right\n",
      "===========================================================\n",
      "Индекс: 136\n",
      "Реальный вид: Setosa\n",
      "-----------------\n",
      "Результаты нейросети:\n",
      "Setosa: 98.62086186446925%\n",
      "Versicolor: 0.40523129187184015%\n",
      "Virginica: 1.3973328399472185%\n",
      "right\n",
      "===========================================================\n",
      "Индекс: 137\n",
      "Реальный вид: Virginica\n",
      "-----------------\n",
      "Результаты нейросети:\n",
      "Setosa: 1.059297927325372%\n",
      "Versicolor: 17.176984971895116%\n",
      "Virginica: 83.62908374449357%\n",
      "right\n",
      "===========================================================\n",
      "Индекс: 138\n",
      "Реальный вид: Setosa\n",
      "-----------------\n",
      "Результаты нейросети:\n",
      "Setosa: 98.15334840289268%\n",
      "Versicolor: 0.4412203132630764%\n",
      "Virginica: 1.7554558438605576%\n",
      "right\n",
      "===========================================================\n",
      "Индекс: 139\n",
      "Реальный вид: Versicolor\n",
      "-----------------\n",
      "Результаты нейросети:\n",
      "Setosa: 0.6661304218108507%\n",
      "Versicolor: 93.48588976731261%\n",
      "Virginica: 6.118012951198254%\n",
      "right\n",
      "===========================================================\n",
      "Индекс: 140\n",
      "Реальный вид: Versicolor\n",
      "-----------------\n",
      "Результаты нейросети:\n",
      "Setosa: 1.2768557414125492%\n",
      "Versicolor: 8.0072071077196%\n",
      "Virginica: 91.14532214418155%\n",
      "wrong\n",
      "===========================================================\n",
      "Индекс: 141\n",
      "Реальный вид: Virginica\n",
      "-----------------\n",
      "Результаты нейросети:\n",
      "Setosa: 5.520118454052896%\n",
      "Versicolor: 0.203720179676865%\n",
      "Virginica: 99.69075384398498%\n",
      "right\n",
      "===========================================================\n",
      "Индекс: 142\n",
      "Реальный вид: Setosa\n",
      "-----------------\n",
      "Результаты нейросети:\n",
      "Setosa: 93.834031058992%\n",
      "Versicolor: 0.5455061362795779%\n",
      "Virginica: 5.495563124627816%\n",
      "right\n",
      "===========================================================\n",
      "Индекс: 143\n",
      "Реальный вид: Setosa\n",
      "-----------------\n",
      "Результаты нейросети:\n",
      "Setosa: 96.50035161566889%\n",
      "Versicolor: 0.49930904890873007%\n",
      "Virginica: 3.1356904554128024%\n",
      "right\n",
      "===========================================================\n",
      "Индекс: 144\n",
      "Реальный вид: Setosa\n",
      "-----------------\n",
      "Результаты нейросети:\n",
      "Setosa: 97.91094165676456%\n",
      "Versicolor: 0.45204099026747807%\n",
      "Virginica: 1.9528823082666167%\n",
      "right\n",
      "===========================================================\n",
      "Индекс: 145\n",
      "Реальный вид: Setosa\n",
      "-----------------\n",
      "Результаты нейросети:\n",
      "Setosa: 98.23343459225728%\n",
      "Versicolor: 0.4369815036111039%\n",
      "Virginica: 1.684908234401978%\n",
      "right\n",
      "===========================================================\n",
      "Индекс: 146\n",
      "Реальный вид: Virginica\n",
      "-----------------\n",
      "Результаты нейросети:\n",
      "Setosa: 5.484903537574961%\n",
      "Versicolor: 0.2104061482864552%\n",
      "Virginica: 99.68291401169584%\n",
      "right\n",
      "===========================================================\n",
      "Индекс: 147\n",
      "Реальный вид: Setosa\n",
      "-----------------\n",
      "Результаты нейросети:\n",
      "Setosa: 98.91308941204628%\n",
      "Versicolor: 0.39598556346647623%\n",
      "Virginica: 1.099383758599222%\n",
      "right\n",
      "===========================================================\n",
      "Индекс: 148\n",
      "Реальный вид: Setosa\n",
      "-----------------\n",
      "Результаты нейросети:\n",
      "Setosa: 99.16772919878345%\n",
      "Versicolor: 0.37611204390751507%\n",
      "Virginica: 0.8514463661430987%\n",
      "right\n",
      "===========================================================\n",
      "Индекс: 149\n",
      "Реальный вид: Setosa\n",
      "-----------------\n",
      "Результаты нейросети:\n",
      "Setosa: 97.486768739339%\n",
      "Versicolor: 0.4598732681700592%\n",
      "Virginica: 2.3940661374161754%\n",
      "right\n",
      "===========================================================\n",
      "Точность: 93.33333333333333%\n"
     ]
    }
   ],
   "source": [
    "# до активации нейронов preActiv[x][y]\n",
    "# x - индекс слоя (слои считаются с первого скрытого слоя)\n",
    "# y - индекс нейрона в слое\n",
    "preActiv = np.zeros((len(neuron_count) - 1, max_neuron_count))\n",
    "# после активациии нейронов postActiv[x][y]\n",
    "# x - индекс слоя (слои считаются с входного слоя)\n",
    "# y - индекс нейрона в слое\n",
    "postActiv = np.zeros((len(neuron_count), max_neuron_count))\n",
    "\n",
    "right = 0\n",
    "pred = 0\n",
    "res = np.zeros((kohonen_neuron_count))\n",
    "for el in test_data:\n",
    "    \n",
    "    # получаем нормализованный входной вектор со слоя Кохонена\n",
    "    test_el = getKohonenNormResult(el['features'], kohonen_neuron_count, kohonen_w)\n",
    "    \n",
    "    # инициируем входной слой перцептрона (нормализованный вектор слоя кохонена)\n",
    "    for i in range(len(test_el)):\n",
    "        postActiv[0][i] = test_el[i]\n",
    "    \n",
    "    # Проходим по всем слоям\n",
    "    for l in range(len(neuron_count) - 1):\n",
    "        for n_c in range(neuron_count[l + 1]):\n",
    "            preActiv[l][n_c] = np.dot(postActiv[l][0:neuron_count[l]], weights[l][0:neuron_count[l],n_c])\n",
    "            postActiv[l+1][n_c] = activation(preActiv[l][n_c])\n",
    "    \n",
    "    \n",
    "    print('Индекс: ' + el['name'])\n",
    "    print('Реальный вид: ' + classes[np.where(el[\"result\"] == 1)[0][0]])\n",
    "    print('-----------------')\n",
    "    print('Результаты нейросети:')\n",
    "    \n",
    "    result = postActiv[len(neuron_count)-1][0:len(student['result'])]\n",
    "    \n",
    "    best_results = [0.0, 0.0, 0.0]\n",
    "    best_indexes = [0, 1, 2]\n",
    "    max_res = 0.0\n",
    "    max_index = 0\n",
    "    for i in range(len(result)):\n",
    "        if (result[i] > max_res):\n",
    "            max_index = i\n",
    "            max_res = result[i]\n",
    "        \n",
    "#     print(classes[best_indexes[0]] + ': ' + str(result[best_indexes[0]] * 100) + '%')\n",
    "#     print(classes[best_indexes[1]] + ': ' + str(result[best_indexes[1]] * 100) + '%')\n",
    "#     print(classes[best_indexes[2]] + ': ' + str(result[best_indexes[2]] * 100) + '%')\n",
    "    \n",
    "    print(classes[0] + ': ' + str(result[0] * 100) + '%')\n",
    "    print(classes[1] + ': ' + str(result[1] * 100) + '%')\n",
    "    print(classes[2] + ': ' + str(result[2] * 100) + '%')\n",
    "     \n",
    "    if np.where(el['result'] == 1)[0][0] == max_index:\n",
    "        print('right')\n",
    "        right += 1\n",
    "    else:\n",
    "        print('wrong')\n",
    "    print('===========================================================')\n",
    "print ('Точность: ' + str((right / len(test_data)) * 100) + '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
