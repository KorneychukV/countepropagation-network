{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import random\n",
    "import math\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "temp_mse_values = []\n",
    "mse_values = []\n",
    "all_mse_values = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Считывание данных из файла и их подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBdate(bdate):\n",
    "  return datetime.strptime(bdate, '%d.%m.%Y').month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Студенты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop_column = ['№п/п', 'Основание поступления']\n",
    "# gender_dict = {'Мужской': 1,'Женский': 0}\n",
    "\n",
    "# # количество признаков входного слоя\n",
    "# feature_count = 9\n",
    "\n",
    "# # подготовленный датасет\n",
    "# train_data = []\n",
    "# # датасет для тестирования\n",
    "# test_data = []\n",
    "\n",
    "# df = pd.read_csv('data/input.csv', sep=',')\n",
    "# df.drop(drop_column, axis = 1, inplace = True)\n",
    "\n",
    "# # переводим пол в числовой формат, т. к. это будет один из признаков\n",
    "# df['Пол'].replace(gender_dict, inplace = True) \n",
    "\n",
    "# # приводим баллы по ЕГЭ к диапозону от 0 до 1\n",
    "# df.astype({'Баллы ЕГЭ': 'float'}).dtypes\n",
    "# df['Баллы ЕГЭ'] /= 100\n",
    "    \n",
    "# fios = df['ФИО'].unique()\n",
    "# subjects = df['Предметы ЕГЭ'].unique()\n",
    "# cities = df['Населенный пункт по прописке'].unique()\n",
    "# schools = df['Учебное заведение'].unique()\n",
    "# classes = df['Специальность/направление'].unique()\n",
    "\n",
    "# for el in fios:\n",
    "#     student = df[df['ФИО'] == el]\n",
    "#     features = np.zeros((feature_count))\n",
    "#     for i in range(len(subjects)):\n",
    "#         res = student.loc[student['Предметы ЕГЭ'] == subjects[i], 'Баллы ЕГЭ'].values\n",
    "#         features[i] = res[0] if len(res) else 0\n",
    "#     features[5] = student.iloc[0]['Пол']\n",
    "#     features[6] = getBdate(student.iloc[0]['Дата рождения']) / 12\n",
    "    \n",
    "#     city_index = np.where(cities == student.iloc[0]['Населенный пункт по прописке'])[0]\n",
    "#     features[7] = 0 if len(city_index) == 0 else city_index[0]/len(cities)\n",
    "    \n",
    "#     school_number = np.where(schools == student.iloc[0]['Учебное заведение'])[0]\n",
    "#     features[8] = 0 if len(school_number) == 0 else school_number[0]/len(schools)\n",
    "    \n",
    "#     # Нормализация входного вектора\n",
    "# #     norm_features = np.zeros((feature_count))\n",
    "# #     for i in range(len(features)):\n",
    "# #         sum = 0 \n",
    "# #         for j in range(len(features)):\n",
    "# #             sum += features[j] ** 2\n",
    "# #         norm_features[i] = features[i] / math.sqrt(sum)\n",
    "#     norm_features = (features * features.mean()) / features.std()\n",
    "    \n",
    "#     res = np.zeros((len(classes)))\n",
    "#     res[np.where(classes == student.iloc[0]['Специальность/направление'])[0].item(0)] = 1\n",
    "    \n",
    "    \n",
    "    \n",
    "#     # Нормализованные\n",
    "#     temp_data = dict(fio = el, features = norm_features, result = res)\n",
    "#     # Не нормализованные\n",
    "#     #temp_data = dict(fio = el, features = features, result = res)\n",
    "    \n",
    "#     # 90% - train, 10% - test\n",
    "#     if (len(train_data) / len(fios)) < 0.9:\n",
    "#         train_data.append(temp_data)\n",
    "#     else:\n",
    "#         train_data.append(temp_data)\n",
    "#         test_data.append(temp_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Студенты (информатика)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# количество признаков входного слоя\n",
    "feature_count = 3\n",
    "\n",
    "# подготовленный датасет\n",
    "train_data = []\n",
    "# датасет для тестирования\n",
    "test_data = []\n",
    "\n",
    "drop_column = ['№п/п', 'Основание поступления']\n",
    "gender_dict = {'Мужской': 1,'Женский': 0}\n",
    "\n",
    "df = pd.read_csv('data/input.csv', sep=',')\n",
    "df.drop(drop_column, axis = 1, inplace = True)\n",
    "\n",
    "# переводим пол в числовой формат, т. к. это будет один из признаков\n",
    "df['Пол'].replace(gender_dict, inplace = True) \n",
    "\n",
    "# приводим баллы по ЕГЭ к диапозону от 0 до 1\n",
    "df.astype({'Баллы ЕГЭ': 'float'}).dtypes\n",
    "df['Баллы ЕГЭ'] /= 100\n",
    "\n",
    "# Смотрим только для информатики\n",
    "fios = df.loc[df['Предметы ЕГЭ'] == 'Информатика и ИКТ', 'ФИО']\n",
    "classes = df.loc[df['Предметы ЕГЭ'] == 'Информатика и ИКТ', 'Специальность/направление'].unique()\n",
    "subjects = df.loc[df['Специальность/направление'].isin(classes), 'Предметы ЕГЭ'].unique()\n",
    "\n",
    "for el in fios:\n",
    "    student = df[df['ФИО'] == el]\n",
    "    features = np.zeros((feature_count))\n",
    "    for i in range(len(subjects)):\n",
    "        res = student.loc[student['Предметы ЕГЭ'] == subjects[i], 'Баллы ЕГЭ'].values\n",
    "        features[i] = res[0] if len(res) else 0\n",
    "    \n",
    "    # Нормализация входного вектора\n",
    "    norm_features = np.zeros((feature_count))\n",
    "    for i in range(len(features)):\n",
    "        sum = 0 \n",
    "        for j in range(len(features)):\n",
    "            sum += features[j] ** 2\n",
    "        norm_features[i] = features[i] / math.sqrt(sum)\n",
    "    \n",
    "    res = np.zeros((len(classes)))\n",
    "    res[np.where(classes == student.iloc[0]['Специальность/направление'])[0][0]] = 1\n",
    "    \n",
    "    # Нормализованные\n",
    "    temp_data = dict(fio = el, features = norm_features, result = res)\n",
    "    # Не нормализованные\n",
    "#     temp_data = dict(fio = el, features = features, result = res)\n",
    "    \n",
    "    # 90% - train, 10% - test\n",
    "    if (len(train_data) / len(fios)) < 0.9:\n",
    "        train_data.append(temp_data)\n",
    "    else:\n",
    "        test_data.append(temp_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Титаник"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('data/titanik.csv', sep=',')\n",
    "\n",
    "# # количество признаков входного слоя\n",
    "# feature_count = 5\n",
    "# drop_column = ['Parch', 'Ticket', 'Fare', 'Cabin']\n",
    "\n",
    "# # подготовленный датасет\n",
    "# train_data = []\n",
    "# # датасет для тестирования\n",
    "# test_data = []\n",
    "\n",
    "# classes = df['Survived'].unique()\n",
    "\n",
    "# df['Sex'] = df['Sex'].replace(['male','female'], [0, 1])\n",
    "# df['Embarked'] = df['Embarked'].fillna(('S'))\n",
    "# df['Embarked'] = df['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
    "\n",
    "# df['Pclass'] = df['Pclass'].fillna(np.mean(df['Pclass']))\n",
    "# df['Pclass'] = df['Pclass']/max(df['Pclass'])\n",
    "\n",
    "# df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "# df['Age'] = df['Age']/max(df['Age'])\n",
    "\n",
    "# df['SibSp'] = df['SibSp'].fillna(df['SibSp'].median())\n",
    "# df['SibSp'] = df['SibSp']/max(df['SibSp'])\n",
    "\n",
    "\n",
    "# vectors = []\n",
    "\n",
    "# for i in range(len(df)) : \n",
    "\n",
    "#     features = np.zeros((feature_count))\n",
    "#     features[0] = df.loc[i, 'Sex']\n",
    "#     features[1] = df.loc[i, 'Embarked']\n",
    "#     features[2] = df.loc[i, 'Pclass']\n",
    "#     features[3] = df.loc[i, 'Age']\n",
    "#     features[4] = df.loc[i, 'SibSp']\n",
    "    \n",
    "#     # Нормализация входного вектора\n",
    "# #     norm_features = np.zeros((feature_count))\n",
    "# #     for j in range(len(features)):\n",
    "# #         sum = 0 \n",
    "# #         for k in range(len(features)):\n",
    "# #             sum += features[k] ** 2\n",
    "# #         norm_features[j] = features[j] / math.sqrt(sum)\n",
    "    \n",
    "#     norm_features = (features * features.mean()) / features.std()\n",
    "    \n",
    "#     # Нормализованные    \n",
    "#     temp_data = dict(name = df.loc[i, 'Name'], \n",
    "#                      features = norm_features, \n",
    "#                      result = np.where(classes == df.loc[i, \"Survived\"])[0])\n",
    "    \n",
    "#     # Не нормализованные    \n",
    "# #     temp_data = dict(name = df.loc[i, 'Name'], \n",
    "# #                      features = features, \n",
    "# #                      result = np.where(classes == df.loc[i, \"Survived\"])[0])\n",
    "    \n",
    "#     if (len(train_data) / len(df)) < 0.9:\n",
    "#         train_data.append(temp_data)\n",
    "#     else:\n",
    "#         train_data.append(temp_data)\n",
    "#         test_data.append(temp_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ирис"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # количество признаков входного слоя\n",
    "# feature_count = 4\n",
    "\n",
    "# df = pd.read_csv('data/iris.csv', sep=',')\n",
    "\n",
    "# # подготовленный датасет\n",
    "# train_data = []\n",
    "# # датасет для тестирования\n",
    "# test_data = []\n",
    "\n",
    "# classes = df[\"variety\"].unique()\n",
    "\n",
    "# df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# for i in range(len(df)) : \n",
    "\n",
    "#     features = np.zeros((feature_count))\n",
    "#     features[0] = df.loc[i, \"sepal.length\"]\n",
    "#     features[1] = df.loc[i, \"sepal.width\"]\n",
    "#     features[2] = df.loc[i, \"petal.length\"]\n",
    "#     features[3] = df.loc[i, \"petal.width\"]\n",
    "    \n",
    "#     # Нормализация входного вектора\n",
    "#     norm_features = features/np.linalg.norm(features)\n",
    "    \n",
    "#     res = np.zeros((len(classes)))\n",
    "#     res[np.where(classes == df.loc[i, \"variety\"])[0].item(0)] = 1\n",
    "    \n",
    "#     temp_data = dict(name = str(i), \n",
    "#                      features = norm_features, \n",
    "#                      result = res)\n",
    "    \n",
    "#     if (len(train_data) / len(df)) < 0.9:\n",
    "#         train_data.append(temp_data)\n",
    "#         test_data.append(temp_data)\n",
    "#     else:\n",
    "# #         train_data.append(temp_data)\n",
    "#         test_data.append(temp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # количество признаков входного слоя\n",
    "# feature_count = 4\n",
    "\n",
    "# train_data = []\n",
    "# test_data = []\n",
    "\n",
    "# # (x or y) and (k or l) \n",
    "# data = [\n",
    "#     [0, 0, 0, 0, 0],\n",
    "#     [0, 0, 0, 1, 0],\n",
    "#     [0, 0, 1, 0, 0],\n",
    "#     [0, 0, 1, 1, 0],\n",
    "#     [0, 1, 0, 0, 0],\n",
    "#     [0, 1, 0, 1, 1],\n",
    "#     [0, 1, 1, 0, 1],\n",
    "#     [0, 1, 1, 1, 1],\n",
    "#     [1, 0, 0, 0, 0],\n",
    "#     [1, 0, 0, 1, 1],\n",
    "#     [1, 0, 1, 0, 1],\n",
    "#     [1, 0, 1, 1, 1],\n",
    "#     [1, 1, 0, 0, 0],\n",
    "#     [1, 1, 0, 1, 1],\n",
    "#     [1, 1, 1, 0, 1],\n",
    "# ]\n",
    "\n",
    "# t_data = [\n",
    "#     [1, 1, 1, 1, 1],\n",
    "#     [1, 1, 1, 0, 1],\n",
    "#     [1, 0, 0, 1, 1],\n",
    "#     [0, 1, 0, 0, 0],\n",
    "#     [0, 1, 1, 0, 1],\n",
    "#     [0, 1, 0, 1, 1],\n",
    "#     [0, 1, 1, 0, 1],\n",
    "#     [0, 1, 1, 1, 1],\n",
    "#     [1, 0, 0, 0, 0],\n",
    "#     [1, 0, 0, 1, 1],\n",
    "#     [1, 0, 1, 0, 1],\n",
    "#     [1, 0, 1, 0, 1],\n",
    "#     [1, 0, 1, 1, 1],\n",
    "#     [1, 1, 0, 0, 0],\n",
    "#     [0, 1, 0, 1, 1],\n",
    "#     [0, 1, 1, 0, 1],\n",
    "# ]\n",
    "\n",
    "# # data = [\n",
    "# #     [0, 0, 0],\n",
    "# #     [0, 1, 1],\n",
    "# #     [1, 0, 1],\n",
    "# #     [1, 1, 1],\n",
    "# # ]\n",
    "\n",
    "# # t_data = [\n",
    "# #     [0, 0, 0],\n",
    "# #     [0, 1, 1],\n",
    "# #     [1, 0, 1],\n",
    "# #     [1, 1, 1],\n",
    "# # ]\n",
    "\n",
    "# for i in range(len(data)):\n",
    "    \n",
    "#     features = np.zeros((feature_count))\n",
    "#     features[0] = data[i][0]\n",
    "#     features[1] = data[i][1]\n",
    "#     features[2] = data[i][2]\n",
    "#     features[3] = data[i][3]\n",
    "#     temp_data = dict(name = 'xor1', \n",
    "#                      features = features, \n",
    "#                      result = np.array(([data[i][4]])))\n",
    "#     train_data.append(temp_data)\n",
    "    \n",
    "#     features[0] = t_data[i][0]\n",
    "#     features[1] = t_data[i][1]\n",
    "#     features[2] = t_data[i][2]\n",
    "#     features[3] = t_data[i][3]\n",
    "#     temp_data = dict(name = 'xor1', \n",
    "#                      features = features, \n",
    "#                      result = np.array(([t_data[i][4]])))\n",
    "#     test_data.append(temp_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Кохонен"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getKohonenWinnerIndex(x, neuron_counts, w, s):\n",
    "    result = 0\n",
    "    max_net = -1\n",
    "    for i in range(neuron_counts):\n",
    "        net = 0\n",
    "        for j in range(len(x)):\n",
    "            net += x[j] * w[j][i] * s[i]\n",
    "        if (net > max_net):\n",
    "            result = i\n",
    "            max_net = net\n",
    "    return result\n",
    "\n",
    "def getKohonenNormResult(x, neuron_counts, w):\n",
    "    result = np.zeros((neuron_counts))\n",
    "    max_index = 0\n",
    "    max_net = -1\n",
    "    \n",
    "    for i in range(neuron_counts):\n",
    "        net = 0\n",
    "        for j in range(len(x)):\n",
    "            net += (x[j]+0.001) * w[j][i]\n",
    "        if (net > max_net):\n",
    "            max_index = i\n",
    "            max_net = net\n",
    "        result[i] = net\n",
    "    \n",
    "    summ = 0\n",
    "    for i in range(neuron_counts):\n",
    "        if i != max_index:\n",
    "            summ += result[i] ** 2\n",
    "    divider = math.sqrt(summ)\n",
    "    \n",
    "    for i in range(neuron_counts):    \n",
    "        if i != max_index:\n",
    "            result[i] /= divider\n",
    "    \n",
    "    result[max_index] = 1\n",
    "    return result\n",
    "\n",
    "def getNeuronNet(x, w):\n",
    "    result = 0\n",
    "    for i in range(len(x)):\n",
    "        result += x[i] * w[i]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# скорость обучения слоя Кохонена\n",
    "# лучший результат для титаника theta = 0.7\n",
    "# лучший результат для ирисок theta = 0.7\n",
    "theta = 0.7\n",
    "# лучший результат для студентов kohonen_neuron_count = 30\n",
    "# лучший результат для титаника kohonen_neuron_count = 15\n",
    "# лучший результат для ирисок kohonen_neuron_count = 15\n",
    "kohonen_neuron_count = 100\n",
    "# штрафы кластеров\n",
    "s_w = np.ones((kohonen_neuron_count))\n",
    "# количество эпох\n",
    "# лучший результат для титаника epoch_count = 20\n",
    "# лучший результат для ирисок epoch_count = 20\n",
    "epoch_count = 100\n",
    "\n",
    "#инициализация начальных весов слоя Кохонена kohonen_w[x][y]\n",
    "# x - индекс нейрона входного слоя\n",
    "# y - индекс нейрона слоя Кохонена\n",
    "kohonen_w = np.random.uniform(-1, 1, (feature_count, kohonen_neuron_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = epoch_count * len(train_data)\n",
    "# Обучение на подготовленном датасете\n",
    "while step >= 0:\n",
    "    \n",
    "    student = train_data[random.randint(0, len(train_data) - 1)]\n",
    "    \n",
    "    # Определение нейрона победителя\n",
    "    winner_index = getKohonenWinnerIndex(student['features'], kohonen_neuron_count, kohonen_w, s_w)\n",
    "    # Увеличиваем штраф, уменьшая его коэффициент\n",
    "    s_w[winner_index] *= 0.995\n",
    "    # Корректировка весов нейрона победителя на слое Кохонена\n",
    "    for i in range(feature_count):\n",
    "        kohonen_w[i][winner_index] += theta * (student['features'][i] - kohonen_w[i][winner_index])\n",
    "    # Изменение скорости обучения\n",
    "    # 0.0003 для титаника\n",
    "    # 0.0003 для ирисок\n",
    "    theta -= (theta * 0.0003)\n",
    "    step -= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Перцептрон"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(net):\n",
    "    return 1.0/(1 + np.exp(-net))\n",
    "\n",
    "def logistic_deriv(x):\n",
    "    return activation(x) * (1 - activation(x))\n",
    "\n",
    "def mse(pred, actual):\n",
    "    return np.square(np.subtract(actual,pred)).mean()\n",
    "\n",
    "def mse_deriv(pred, actual):\n",
    "    return -(2/len(pred)) * np.subtract(actual,pred).sum()\n",
    "\n",
    "def mse_deriv_private(pred, actual):\n",
    "    return -2 * (actual - pred)\n",
    "\n",
    "def get_vector_length(vector):\n",
    "    return math.sqrt(np.square(vector).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "MSE mean: 0.2563217883551139\n",
      "theta: 0.39980000000000004\n",
      "Epoch 1\n",
      "MSE mean: 0.24621101792575892\n",
      "theta: 0.39960010000000007\n",
      "Epoch 2\n",
      "MSE mean: 0.2459786373148349\n",
      "theta: 0.3994002999500001\n",
      "Epoch 3\n",
      "MSE mean: 0.24600354213960812\n",
      "theta: 0.3992005998000251\n",
      "Epoch 4\n",
      "MSE mean: 0.2460455939373277\n",
      "theta: 0.3990009995001251\n",
      "Epoch 5\n",
      "MSE mean: 0.24606920544951638\n",
      "theta: 0.39880149900037504\n",
      "Epoch 6\n",
      "MSE mean: 0.24606601454784377\n",
      "theta: 0.39860209825087484\n",
      "Epoch 7\n",
      "MSE mean: 0.24603298257537315\n",
      "theta: 0.3984027972017494\n",
      "Epoch 8\n",
      "MSE mean: 0.24596762694052374\n",
      "theta: 0.39820359580314857\n",
      "Epoch 9\n",
      "MSE mean: 0.2458666934840158\n",
      "theta: 0.398004494005247\n",
      "Epoch 10\n",
      "MSE mean: 0.24572621973417524\n",
      "theta: 0.39780549175824437\n",
      "Epoch 11\n",
      "MSE mean: 0.2455433967248321\n",
      "theta: 0.39760658901236523\n",
      "Epoch 12\n",
      "MSE mean: 0.24532383993693094\n",
      "theta: 0.39740778571785906\n",
      "Epoch 13\n",
      "MSE mean: 0.24511185027533078\n",
      "theta: 0.39720908182500014\n",
      "Epoch 14\n",
      "MSE mean: 0.24502625697632674\n",
      "theta: 0.39701047728408767\n",
      "Epoch 15\n",
      "MSE mean: 0.2449299199324524\n",
      "theta: 0.3968119720454456\n",
      "Epoch 16\n",
      "MSE mean: 0.24464689743275503\n",
      "theta: 0.3966135660594229\n",
      "Epoch 17\n",
      "MSE mean: 0.2443321628078537\n",
      "theta: 0.39641525927639315\n",
      "Epoch 18\n",
      "MSE mean: 0.24406739689474122\n",
      "theta: 0.39621705164675497\n",
      "Epoch 19\n",
      "MSE mean: 0.2438610269659602\n",
      "theta: 0.3960189431209316\n",
      "Epoch 20\n",
      "MSE mean: 0.2437031006976945\n",
      "theta: 0.39582093364937115\n",
      "Epoch 21\n",
      "MSE mean: 0.24358165776503307\n",
      "theta: 0.3956230231825465\n",
      "Epoch 22\n",
      "MSE mean: 0.24348675766201747\n",
      "theta: 0.39542521167095523\n",
      "Epoch 23\n",
      "MSE mean: 0.24341101655484665\n",
      "theta: 0.3952274990651198\n",
      "Epoch 24\n",
      "MSE mean: 0.2433491838498835\n",
      "theta: 0.39502988531558725\n",
      "Epoch 25\n",
      "MSE mean: 0.24329758040427538\n",
      "theta: 0.39483237037292945\n",
      "Epoch 26\n",
      "MSE mean: 0.24325363294662558\n",
      "theta: 0.39463495418774297\n",
      "Epoch 27\n",
      "MSE mean: 0.243215538827441\n",
      "theta: 0.3944376367106491\n",
      "Epoch 28\n",
      "MSE mean: 0.24318204037684535\n",
      "theta: 0.39424041789229375\n",
      "Epoch 29\n",
      "MSE mean: 0.24315228279157575\n",
      "theta: 0.3940432976833476\n"
     ]
    }
   ],
   "source": [
    "# Обучение перцептрона\n",
    "# 20 для титаника\n",
    "# 20 для ирисок\n",
    "epoch_count = 30\n",
    "\n",
    "per_input_neuron_count = kohonen_neuron_count\n",
    "# per_input_neuron_count = len(train_data[0]['features'])\n",
    "\n",
    "# количество скрытых слоев\n",
    "# 2 для x or y\n",
    "# 1 для титаника\n",
    "# 1 для студентов\n",
    "# 1 для ирисок\n",
    "hiden_layer_count = 2\n",
    "\n",
    "output_neuron_count = len(train_data[0]['result'])\n",
    "\n",
    "# количество нейронов в слоях, последний слой выходной, первый - входной\n",
    "# 8 и 4 для x or y\n",
    "# 25 для титаника\n",
    "# 25 для студентов\n",
    "# 25 для ирисок\n",
    "neuron_count = [per_input_neuron_count, 50, 25, output_neuron_count]\n",
    "max_neuron_count = np.max(neuron_count)\n",
    "layers_count = len(neuron_count)\n",
    "\n",
    "#инициализация начальных весов Перцептрона weights[l][x][y]\n",
    "# l - индекс слоя (слои считаются с первого скрытого слоя)\n",
    "# x - индекс нейрона от которого идёт вес\n",
    "# y - индекс нейрона к которому идёт вес\n",
    "weights = np.random.uniform(-1, 1, (layers_count - 1, max_neuron_count, max_neuron_count))\n",
    "# weights = np.ones((layers_count - 1, max_neuron_count, max_neuron_count))\n",
    "new_weights = np.zeros((layers_count - 1, max_neuron_count, max_neuron_count))\n",
    "\n",
    "# до активации нейронов preActiv[x][y]. Начинает с первого скрытого слоя\n",
    "# x - индекс слоя (слои считаются с первого скрытого слоя)\n",
    "# y - индекс нейрона в слое\n",
    "preActiv = np.zeros((layers_count - 1, max_neuron_count))\n",
    "\n",
    "# после активациии нейронов postActiv[x][y]\n",
    "# x - индекс слоя (слои считаются с входного слоя)\n",
    "# y - индекс нейрона в слое\n",
    "postActiv = np.zeros((layers_count, max_neuron_count))\n",
    "\n",
    "# для вычисления производной postActivDeriv[x][y]\n",
    "# x - индекс слоя (слои считаются с входного слоя)\n",
    "# y - индекс нейрона в слое\n",
    "postActivDeriv = np.zeros((layers_count, max_neuron_count))\n",
    "\n",
    "# ошибка на нейроне\n",
    "# x - индекс слоя (слои считаются с входного слоя)\n",
    "# y - индекс нейрона в слое\n",
    "err = np.zeros((layers_count, np.max(neuron_count[1:len(neuron_count)])))\n",
    "\n",
    "# скорость обучения\n",
    "# 0.1 для x or y\n",
    "# 0.4 для титаника\n",
    "# 0.4 для студентов\n",
    "# 0.4 для ирисок\n",
    "theta = 0.4\n",
    "\n",
    "for ep in range(epoch_count):\n",
    "    print('Epoch ' + str(ep))\n",
    "    for el in range(len(train_data)):\n",
    "    \n",
    "        # получаем нормализованный входной вектор со слоя Кохонена\n",
    "        student = train_data[el]\n",
    "        train_el = getKohonenNormResult(student['features'], kohonen_neuron_count, kohonen_w)\n",
    "\n",
    "        # подаем на вход датасет\n",
    "#         student = train_data[el]\n",
    "#         student = train_data[random.randint(0, len(train_data) - 1)]\n",
    "#         train_el = student['features']\n",
    "\n",
    "        \n",
    "#         print('features------------------------')\n",
    "#         print(student['features'])\n",
    "#         print('Clusters------------------------')\n",
    "#         print(train_el)\n",
    "    \n",
    "        # Подготовка входного вектора\n",
    "        for i in range(len(train_el)):\n",
    "            postActiv[0][i] = train_el[i]\n",
    "\n",
    "        # Прямое распространение\n",
    "        for l in range(layers_count - 1):\n",
    "            for n_c in range(neuron_count[l + 1]):\n",
    "                preActiv[l][n_c] = np.dot(postActiv[l][0:neuron_count[l]], weights[l][0:neuron_count[l],n_c])\n",
    "                postActiv[l+1][n_c] = activation(preActiv[l][n_c])\n",
    "                postActivDeriv[l+1][n_c] = logistic_deriv(preActiv[l][n_c])\n",
    "            \n",
    "                \n",
    "        # Общая ошибка сети\n",
    "        err_common = mse(postActiv[layers_count-1][0:len(student['result'])], student['result'])\n",
    "        \n",
    "        \n",
    "        # Вычисляем производную от функции ошибки на каждом нейроне выходного слоя\n",
    "        for n_c in range(neuron_count[layers_count - 1]):\n",
    "            err[layers_count - 2][n_c] = mse_deriv_private(postActiv[layers_count-1][n_c], student['result'][n_c])\n",
    "        \n",
    "        # Изменение последнего слоя весов (веса от последнего скрытого слоя к выходному слою)\n",
    "        # in_c - индекс нейрона входного слоя\n",
    "        # out_c - индекс нейрона выходного слоя\n",
    "        for in_c in range(neuron_count[layers_count - 2]):\n",
    "            # Производная от взвешенного значения приходящего на нейрон выходного слоя по вычисляемому весу\n",
    "            # т. е. значение нейрона последнего скрытого слоя после функции активации\n",
    "            c = postActiv[layers_count-2][in_c]\n",
    "            for out_c in range(neuron_count[layers_count - 1]):\n",
    "                # Значение производной от функции ошибки на нейроне выходного слоя\n",
    "                a = err[layers_count - 2][out_c]\n",
    "                # Значение производной от функции активации на нейроне выходного слоя\n",
    "                b = postActivDeriv[layers_count-1][out_c]\n",
    "                # Старое значение веса\n",
    "                w = weights[layers_count - 2][in_c, out_c]\n",
    "                new_weights[layers_count - 2][in_c, out_c] = w - theta * a * b * c\n",
    "        \n",
    "        if hiden_layer_count > 0:\n",
    "            # Индексы слоев в обратную сторону\n",
    "            for l in range(layers_count - 3, -1, -1):\n",
    "                # Индексы нейронов от которых идет вес\n",
    "                for in_c in range(neuron_count[l]):\n",
    "                    # Производная от функции активации следующего слоя\n",
    "                    c = postActiv[l-1][in_c]\n",
    "                    # Индексы нейронов к которым идет вес\n",
    "                    for out_c in range(neuron_count[l + 1]):\n",
    "                        # Ошибка идущая на предыдущий слой\n",
    "                        for out_out_c in range(neuron_count[l + 2]):\n",
    "                            a1 = err[l + 2][out_out_c]\n",
    "                            a2 = postActivDeriv[l+2][out_out_c]\n",
    "                            a3 = weights[l+1][out_c][out_out_c]\n",
    "                            err[l+1][out_c] += a1 * a2 * a3\n",
    "                        a = err[l+1][out_c]\n",
    "                        # Производная от функции активации предыдущего слоя\n",
    "                        b = postActivDeriv[l+1][out_c]\n",
    "                        # Старое значение веса\n",
    "                        w = weights[l][in_c, out_c]\n",
    "                        new_weights[l][in_c, out_c] = w - theta * a * b * c\n",
    "#                         print('Weight delta------------------------')\n",
    "#                         print(theta * a * b * c)\n",
    "        \n",
    "        weights = new_weights.copy()\n",
    "        \n",
    "#         print('Prediction------------------------')\n",
    "#         print(postActiv[layers_count-1][0:len(student['result'])])\n",
    "#         print('Real------------------------')\n",
    "#         print(student['result'])\n",
    "#         print('MSE------------------------')\n",
    "#         print(err_common)\n",
    "#         print('==========================')\n",
    "        temp_mse_values.append(err_common)\n",
    "        all_mse_values.append(err_common)\n",
    "    # Изменение скорости обучения\n",
    "    # для x or y theta = 0.0003\n",
    "    # для титаника theta = 0.0005\n",
    "    # для студентов theta = 0.0005\n",
    "    # для ирисок theta = 0.0005\n",
    "    theta -= (theta * 0.0005)\n",
    "    mse_values.append(np.array((temp_mse_values)).mean())\n",
    "    print('MSE mean: ' + str(np.array((temp_mse_values)).mean()))\n",
    "    print('theta: ' + str(theta))\n",
    "    temp_mse_values = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тестирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование студентов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Тестирование перцептрона\n",
    "\n",
    "# # до активации нейронов preActiv[x][y]\n",
    "# # x - индекс слоя (слои считаются с первого скрытого слоя)\n",
    "# # y - индекс нейрона в слое\n",
    "# preActiv = np.zeros((len(neuron_count) - 1, max_neuron_count))\n",
    "# # после активациии нейронов postActiv[x][y]\n",
    "# # x - индекс слоя (слои считаются с входного слоя)\n",
    "# # y - индекс нейрона в слое\n",
    "# postActiv = np.zeros((len(neuron_count), max_neuron_count))\n",
    "    \n",
    "# y_pred = 0\n",
    "# y_real = len(test_data)\n",
    "# accuracy = 0\n",
    "# for el in range(len(test_data)):\n",
    "   \n",
    "#     # получаем нормализованный входной вектор со слоя Кохонена\n",
    "#     student = test_data[el]\n",
    "#     test_el = getKohonenNormResult(student['features'], kohonen_neuron_count, kohonen_w)    \n",
    "\n",
    "#     # подаем на вход интересующее значение\n",
    "# #     student = test_data[el]\n",
    "# #     test_el = student['features']\n",
    "\n",
    "#     for i in range(len(test_el)):\n",
    "#         postActiv[0][i] = test_el[i]\n",
    "\n",
    "#     # Проходим по всем слоям\n",
    "#     for l in range(len(neuron_count) - 1):\n",
    "#         for n_c in range(neuron_count[l + 1]):\n",
    "#             preActiv[l][n_c] = np.dot(postActiv[l][0:neuron_count[l]], weights[l][0:neuron_count[l],n_c])\n",
    "#             postActiv[l+1][n_c] = activation(preActiv[l][n_c])    \n",
    "\n",
    "#     print(student['fio'])\n",
    "#     print('Поступил на специальность: ' + classes[np.where(student['result'] == 1)[0][0]])\n",
    "#     print('Результаты нейросети:')\n",
    "#     result = postActiv[len(neuron_count)-1][0:len(student['result'])]\n",
    "    \n",
    "    \n",
    "#     best_results = [0.0, 0.0, 0.0]\n",
    "#     best_indexes = [0, 1, 2]\n",
    "#     max_res = 0.0\n",
    "#     max_index = 0\n",
    "#     for i in range(len(result)):\n",
    "# #         print(classes[i] + ' - ' + str(result[i] * 100) + '%')\n",
    "# #         print('-------------')\n",
    "#         if (result[i] > best_results[0]):\n",
    "#             best_results[2] = best_results[1]\n",
    "#             best_results[1] = best_results[0]\n",
    "#             best_results[0] = result[i]\n",
    "#             best_indexes[2] = best_indexes[1]\n",
    "#             best_indexes[1] = best_indexes[0]\n",
    "#             best_indexes[0] = i\n",
    "#         elif (result[i] > best_results[1]):\n",
    "#             best_results[2] = best_results[1]\n",
    "#             best_results[1] = result[i]\n",
    "#             best_indexes[2] = best_indexes[1]\n",
    "#             best_indexes[1] = i\n",
    "#         elif (result[i] > best_results[2]):\n",
    "#             best_results[2] = result[i]\n",
    "#             best_indexes[2] = i\n",
    "        \n",
    "#     print(classes[best_indexes[0]] + ': ' + str(result[best_indexes[0]] * 100) + '%')\n",
    "#     print(classes[best_indexes[1]] + ': ' + str(result[best_indexes[1]] * 100) + '%')\n",
    "#     print(classes[best_indexes[2]] + ': ' + str(result[best_indexes[2]] * 100) + '%')\n",
    "    \n",
    "#     if (np.where(student['result'] == 1)[0][0] in best_indexes):\n",
    "#         accuracy += 1\n",
    "        \n",
    "#     print()\n",
    "#     print('=================================================')\n",
    "#     print()\n",
    "\n",
    "# print('Точность: ' + str(accuracy / y_real * 100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование студентов (информатика)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Федотов Денис Владимирович\n",
      "Поступил на специальность: Программная инженерия\n",
      "Результаты нейросети:\n",
      "Информатика и вычислительная техника: 48.05012438196246%\n",
      "Прикладная информатика (в экономике): 32.85863625882188%\n",
      "Программная инженерия: 11.74484854634105%\n",
      "-------------------\n",
      "Программная инженерия: 11.74484854634105%\n",
      "\n",
      "=================================================\n",
      "\n",
      "Фролов Михаил Сергеевич\n",
      "Поступил на специальность: Информатика и вычислительная техника\n",
      "Результаты нейросети:\n",
      "Информатика и вычислительная техника: 47.842213613534%\n",
      "Прикладная информатика (в экономике): 33.34711894074775%\n",
      "Программная инженерия: 11.77353535882945%\n",
      "-------------------\n",
      "Информатика и вычислительная техника: 47.842213613534%\n",
      "\n",
      "=================================================\n",
      "\n",
      "Хисамиев Харис Мурадович\n",
      "Поступил на специальность: Информатика и вычислительная техника\n",
      "Результаты нейросети:\n",
      "Информатика и вычислительная техника: 48.02903975438129%\n",
      "Прикладная информатика (в экономике): 32.60383908990843%\n",
      "Программная инженерия: 11.78273370875222%\n",
      "-------------------\n",
      "Информатика и вычислительная техника: 48.02903975438129%\n",
      "\n",
      "=================================================\n",
      "\n",
      "Хлесткова Мария Александровна\n",
      "Поступил на специальность: Информатика и вычислительная техника\n",
      "Результаты нейросети:\n",
      "Информатика и вычислительная техника: 48.07272552450857%\n",
      "Прикладная информатика (в экономике): 32.22888651911126%\n",
      "Программная инженерия: 11.819950559780139%\n",
      "-------------------\n",
      "Информатика и вычислительная техника: 48.07272552450857%\n",
      "\n",
      "=================================================\n",
      "\n",
      "Хромов Никита Владимирович\n",
      "Поступил на специальность: Прикладная информатика (в экономике)\n",
      "Результаты нейросети:\n",
      "Информатика и вычислительная техника: 47.77647986466394%\n",
      "Прикладная информатика (в экономике): 33.65253089203219%\n",
      "Программная инженерия: 11.756287011627972%\n",
      "-------------------\n",
      "Прикладная информатика (в экономике): 33.65253089203219%\n",
      "\n",
      "=================================================\n",
      "\n",
      "Чистенькин Евгений Владиславович\n",
      "Поступил на специальность: Программная инженерия\n",
      "Результаты нейросети:\n",
      "Информатика и вычислительная техника: 47.75802215671527%\n",
      "Прикладная информатика (в экономике): 33.565582386422236%\n",
      "Программная инженерия: 11.76648541280346%\n",
      "-------------------\n",
      "Программная инженерия: 11.76648541280346%\n",
      "\n",
      "=================================================\n",
      "\n",
      "Чунаков Михаил Алексеевич\n",
      "Поступил на специальность: Информатика и вычислительная техника\n",
      "Результаты нейросети:\n",
      "Информатика и вычислительная техника: 47.83713255804442%\n",
      "Прикладная информатика (в экономике): 33.337065563835196%\n",
      "Программная инженерия: 11.777531032759354%\n",
      "-------------------\n",
      "Информатика и вычислительная техника: 47.83713255804442%\n",
      "\n",
      "=================================================\n",
      "\n",
      "Шабанов Руслан Романович\n",
      "Поступил на специальность: Информатика и вычислительная техника\n",
      "Результаты нейросети:\n",
      "Информатика и вычислительная техника: 47.829289150292524%\n",
      "Прикладная информатика (в экономике): 33.23243745600195%\n",
      "Программная инженерия: 11.79323856605848%\n",
      "-------------------\n",
      "Информатика и вычислительная техника: 47.829289150292524%\n",
      "\n",
      "=================================================\n",
      "\n",
      "Шадрин Олег Павлович\n",
      "Поступил на специальность: Информатика и вычислительная техника\n",
      "Результаты нейросети:\n",
      "Информатика и вычислительная техника: 48.05087481160466%\n",
      "Прикладная информатика (в экономике): 32.867538955470316%\n",
      "Программная инженерия: 11.742515152883696%\n",
      "-------------------\n",
      "Информатика и вычислительная техника: 48.05087481160466%\n",
      "\n",
      "=================================================\n",
      "\n",
      "Шевелев Александр Михайлович\n",
      "Поступил на специальность: Информатика и вычислительная техника\n",
      "Результаты нейросети:\n",
      "Информатика и вычислительная техника: 47.70726320717979%\n",
      "Прикладная информатика (в экономике): 33.4402298220101%\n",
      "Программная инженерия: 11.849440364076683%\n",
      "-------------------\n",
      "Информатика и вычислительная техника: 47.70726320717979%\n",
      "\n",
      "=================================================\n",
      "\n",
      "Щербаков Даниил Павлович\n",
      "Поступил на специальность: Прикладная информатика (в экономике)\n",
      "Результаты нейросети:\n",
      "Информатика и вычислительная техника: 47.93809133845255%\n",
      "Прикладная информатика (в экономике): 33.28946805768351%\n",
      "Программная инженерия: 11.726754509987593%\n",
      "-------------------\n",
      "Прикладная информатика (в экономике): 33.28946805768351%\n",
      "\n",
      "=================================================\n",
      "\n",
      "Ювченко Давид Андреевич\n",
      "Поступил на специальность: Программная инженерия\n",
      "Результаты нейросети:\n",
      "Информатика и вычислительная техника: 48.0499222570736%\n",
      "Прикладная информатика (в экономике): 32.85447568806127%\n",
      "Программная инженерия: 11.74576949875172%\n",
      "-------------------\n",
      "Программная инженерия: 11.74576949875172%\n",
      "\n",
      "=================================================\n",
      "\n",
      "Юсупов Кирилл Олегович\n",
      "Поступил на специальность: Информатика и вычислительная техника\n",
      "Результаты нейросети:\n",
      "Информатика и вычислительная техника: 47.65658371181017%\n",
      "Прикладная информатика (в экономике): 33.59079481264233%\n",
      "Программная инженерия: 11.815608983406221%\n",
      "-------------------\n",
      "Информатика и вычислительная техника: 47.65658371181017%\n",
      "\n",
      "=================================================\n",
      "\n",
      "Яблокова Полина Николаевна\n",
      "Поступил на специальность: Прикладная информатика (в экономике)\n",
      "Результаты нейросети:\n",
      "Информатика и вычислительная техника: 47.81090558551331%\n",
      "Прикладная информатика (в экономике): 33.55095776733981%\n",
      "Программная инженерия: 11.753120394300637%\n",
      "-------------------\n",
      "Прикладная информатика (в экономике): 33.55095776733981%\n",
      "\n",
      "=================================================\n",
      "\n",
      "Янюк Дарья Андреевна\n",
      "Поступил на специальность: Программная инженерия\n",
      "Результаты нейросети:\n",
      "Информатика и вычислительная техника: 48.10429365040446%\n",
      "Прикладная информатика (в экономике): 32.63554400429859%\n",
      "Программная инженерия: 11.728318198424887%\n",
      "-------------------\n",
      "Программная инженерия: 11.728318198424887%\n",
      "\n",
      "=================================================\n",
      "\n",
      "Точность: 53.333333333333336%\n"
     ]
    }
   ],
   "source": [
    "# Тестирование перцептрона\n",
    "\n",
    "# до активации нейронов preActiv[x][y]\n",
    "# x - индекс слоя (слои считаются с первого скрытого слоя)\n",
    "# y - индекс нейрона в слое\n",
    "preActiv = np.zeros((len(neuron_count) - 1, max_neuron_count))\n",
    "# после активациии нейронов postActiv[x][y]\n",
    "# x - индекс слоя (слои считаются с входного слоя)\n",
    "# y - индекс нейрона в слое\n",
    "postActiv = np.zeros((len(neuron_count), max_neuron_count))\n",
    "    \n",
    "y_pred = 0\n",
    "y_real = len(test_data)\n",
    "accuracy = 0\n",
    "for el in range(len(test_data)):\n",
    "   \n",
    "    # получаем нормализованный входной вектор со слоя Кохонена\n",
    "    student = test_data[el]\n",
    "    test_el = getKohonenNormResult(student['features'], kohonen_neuron_count, kohonen_w)    \n",
    "\n",
    "    for i in range(len(test_el)):\n",
    "        postActiv[0][i] = test_el[i]\n",
    "\n",
    "    # Проходим по всем слоям\n",
    "    for l in range(len(neuron_count) - 1):\n",
    "        for n_c in range(neuron_count[l + 1]):\n",
    "            preActiv[l][n_c] = np.dot(postActiv[l][0:neuron_count[l]], weights[l][0:neuron_count[l],n_c])\n",
    "            postActiv[l+1][n_c] = activation(preActiv[l][n_c])    \n",
    "\n",
    "    print(student['fio'])\n",
    "    print('Поступил на специальность: ' + classes[np.where(student['result'] == 1)[0][0]])\n",
    "    print('Результаты нейросети:')\n",
    "    result = postActiv[len(neuron_count)-1][0:len(student['result'])]\n",
    "    \n",
    "    max_res = 0.0\n",
    "    max_index = 0\n",
    "    for i in range(len(result)):\n",
    "#         print(classes[i] + ' - ' + str(result[i] * 100) + '%')\n",
    "#         print('-------------')\n",
    "        if (result[i] > max_res):\n",
    "            max_index = i\n",
    "            max_res = result[i]\n",
    "        \n",
    "    print(classes[0] + ': ' + str(result[0] * 100) + '%')\n",
    "    print(classes[1] + ': ' + str(result[1] * 100) + '%')\n",
    "    print(classes[2] + ': ' + str(result[2] * 100) + '%')\n",
    "    print('-------------------')\n",
    "    print(classes[np.where(student['result'] == 1)[0][0]] + ': ' + str(result[np.where(student['result'] == 1)[0][0]] * 100) + '%')\n",
    "    \n",
    "    if (np.where(student['result'] == 1)[0][0] == max_index):\n",
    "        accuracy += 1\n",
    "        \n",
    "    print()\n",
    "    print('=================================================')\n",
    "    print()\n",
    "\n",
    "print('Точность: ' + str(accuracy / y_real * 100) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Света\n",
    "# #инф 64\n",
    "# #русский 70\n",
    "# #математика 79\n",
    "\n",
    "# # Егор\n",
    "# # 54 физика\n",
    "# # 70 математика\n",
    "# # 98 русский\n",
    "\n",
    "# tester = np.array([0.70, 0.0, 0.98, 0.54, 0.0, 1.0, 0.25, 0.05555, 0.06796])\n",
    "# norm_features = (tester * tester.mean()) / tester.std()\n",
    "# norm_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # получаем нормализованный входной вектор со слоя Кохонена\n",
    "# test_el = getKohonenNormResult(norm_features, kohonen_neuron_count, kohonen_w)    \n",
    "\n",
    "# for i in range(len(test_el)):\n",
    "#     postActiv[0][i] = test_el[i]\n",
    "\n",
    "# # Проходим по всем слоям\n",
    "# for l in range(len(neuron_count) - 1):\n",
    "#     for n_c in range(neuron_count[l + 1]):\n",
    "#         preActiv[l][n_c] = np.dot(postActiv[l][0:neuron_count[l]], weights[l][0:neuron_count[l],n_c])\n",
    "#         postActiv[l+1][n_c] = activation(preActiv[l][n_c])    \n",
    "\n",
    "# print('Результаты нейросети:')\n",
    "# result = postActiv[len(neuron_count)-1][0:21]\n",
    "    \n",
    "# best_results = [0.0, 0.0, 0.0]\n",
    "# best_indexes = [0, 1, 2]\n",
    "# max_res = 0.0\n",
    "# max_index = 0\n",
    "# for i in range(len(result)):\n",
    "#     if (result[i] > best_results[0]):\n",
    "#         best_results[2] = best_results[1]\n",
    "#         best_results[1] = best_results[0]\n",
    "#         best_results[0] = result[i]\n",
    "#         best_indexes[2] = best_indexes[1]\n",
    "#         best_indexes[1] = best_indexes[0]\n",
    "#         best_indexes[0] = i\n",
    "#     elif (result[i] > best_results[1]):\n",
    "#         best_results[2] = best_results[1]\n",
    "#         best_results[1] = result[i]\n",
    "#         best_indexes[2] = best_indexes[1]\n",
    "#         best_indexes[1] = i\n",
    "#     elif (result[i] > best_results[2]):\n",
    "#         best_results[2] = result[i]\n",
    "#         best_indexes[2] = i\n",
    "        \n",
    "# print(classes[best_indexes[0]] + ': ' + str(result[best_indexes[0]] * 100) + '%')\n",
    "# print(classes[best_indexes[1]] + ': ' + str(result[best_indexes[1]] * 100) + '%')\n",
    "# print(classes[best_indexes[2]] + ': ' + str(result[best_indexes[2]] * 100) + '%')\n",
    "# print('-------------')\n",
    "# print(classes[9] + ': ' + str(postActiv[len(neuron_count)-1][9] * 100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование титаника"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Тестирование перцептрона\n",
    "\n",
    "# # до активации нейронов preActiv[x][y]\n",
    "# # x - индекс слоя (слои считаются с первого скрытого слоя)\n",
    "# # y - индекс нейрона в слое\n",
    "# preActiv = np.zeros((len(neuron_count) - 1, max_neuron_count))\n",
    "# # после активациии нейронов postActiv[x][y]\n",
    "# # x - индекс слоя (слои считаются с входного слоя)\n",
    "# # y - индекс нейрона в слое\n",
    "# postActiv = np.zeros((len(neuron_count), max_neuron_count))\n",
    "    \n",
    "# right = 0\n",
    "# y_real = len(test_data)\n",
    "# for i in range(len(test_data)):\n",
    "   \n",
    "# #     получаем нормализованный входной вектор со слоя Кохонена\n",
    "#     student = test_data[i]\n",
    "#     test_el = getKohonenNormResult(student['features'], kohonen_neuron_count, kohonen_w)    \n",
    "\n",
    "#     # подаем на вход интересующее значение\n",
    "# #     student = test_data[i]\n",
    "# #     test_el = student['features']\n",
    "\n",
    "#     for i in range(len(test_el)):\n",
    "#         postActiv[0][i] = test_el[i]\n",
    "\n",
    "#     # Проходим по всем слоям\n",
    "#     for l in range(len(neuron_count) - 1):\n",
    "#         for n_c in range(neuron_count[l + 1]):\n",
    "#             preActiv[l][n_c] = np.dot(postActiv[l][0:neuron_count[l]], weights[l][0:neuron_count[l],n_c])\n",
    "#             postActiv[l+1][n_c] = activation(preActiv[l][n_c])    \n",
    "\n",
    "#     print(student['name'])\n",
    "#     print(student['features'])\n",
    "#     print(student['result'])\n",
    "#     print('Результаты нейросети:')\n",
    "#     result = postActiv[len(neuron_count)-1][0:len(student['result'])]\n",
    "#     pred = 0\n",
    "#     print(str(result[0] * 100) + '%')\n",
    "# #     print(str(result))\n",
    "#     if (result[0] * 100) > 50:\n",
    "#         pred = 1\n",
    "#     if (student['result'][0] == pred):\n",
    "#         right += 1\n",
    "        \n",
    "#     print()\n",
    "#     print('=================================================')\n",
    "#     print()\n",
    "# print('Result ' + str((right / y_real)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(len(mse_values))\n",
    "plt.plot(mse_values)\n",
    "plt.ylabel('MSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование ирисок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # до активации нейронов preActiv[x][y]\n",
    "# # x - индекс слоя (слои считаются с первого скрытого слоя)\n",
    "# # y - индекс нейрона в слое\n",
    "# preActiv = np.zeros((len(neuron_count) - 1, max_neuron_count))\n",
    "# # после активациии нейронов postActiv[x][y]\n",
    "# # x - индекс слоя (слои считаются с входного слоя)\n",
    "# # y - индекс нейрона в слое\n",
    "# postActiv = np.zeros((len(neuron_count), max_neuron_count))\n",
    "\n",
    "# right = 0\n",
    "# pred = 0\n",
    "# res = np.zeros((kohonen_neuron_count))\n",
    "# for el in test_data:\n",
    "    \n",
    "#     test_el = getKohonenNormResult(el['features'], kohonen_neuron_count, kohonen_w)\n",
    "    \n",
    "#     for i in range(len(test_el)):\n",
    "#         postActiv[0][i] = test_el[i]\n",
    "    \n",
    "#     # Проходим по всем слоям\n",
    "#     for l in range(len(neuron_count) - 1):\n",
    "#         for n_c in range(neuron_count[l + 1]):\n",
    "#             preActiv[l][n_c] = np.dot(postActiv[l][0:neuron_count[l]], weights[l][0:neuron_count[l],n_c])\n",
    "#             postActiv[l+1][n_c] = activation(preActiv[l][n_c])\n",
    "    \n",
    "#     print('Индекс: ' + test_el['name'])\n",
    "#     print('Это вид: ' + classes[np.where(test_el[\"result\"] == 1)[0][0]])\n",
    "#     print('Результаты нейросети:')\n",
    "    \n",
    "#     result = postActiv[len(neuron_count)-1][0:len(student['result'])]\n",
    "#     for i in range(len(result)):\n",
    "#     temp = 0\n",
    "#     max_res = grossberg_w[winner_index][0] * 100\n",
    "#     max_index = 0\n",
    "#     for i in range(grossberg_neuron_counts):\n",
    "#         result = grossberg_w[winner_index][i] * 100\n",
    "#         if max_res < result:\n",
    "#             max_res, max_index = result, i\n",
    "#         print(classes[i] + ': ' + str(result) + '%')\n",
    "     \n",
    "#     if np.where(test_el['result'] == 1)[0][0] == max_index:\n",
    "#         print('right')\n",
    "#         right += 1\n",
    "#     print('--------------------------------------------------')\n",
    "# print ('Точность: ' + str((right / len(test_data)) * 100) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Тестирование перцептрона\n",
    "    \n",
    "# for el in range(len(test_data)):\n",
    "\n",
    "#     print(student['fio'])\n",
    "#     print('Поступил на специальность: ' + classes[np.where(student['result'] == 1)[0][0]])\n",
    "#     print('Результаты нейросети:')\n",
    "#     result = postActiv[len(neuron_count)-1][0:len(student['result'])]\n",
    "    \n",
    "    \n",
    "#     best_results = [0.0, 0.0, 0.0]\n",
    "#     best_indexes = [0, 1, 2]\n",
    "#     max_res = 0.0\n",
    "#     max_index = 0\n",
    "#     for i in range(len(result)):\n",
    "# #         print(classes[i] + ' - ' + str(result[i] * 100) + '%')\n",
    "# #         print('-------------')\n",
    "#         if (result[i] > best_results[0]):\n",
    "#             best_results[2] = best_results[1]\n",
    "#             best_results[1] = best_results[0]\n",
    "#             best_results[0] = result[i]\n",
    "#             best_indexes[2] = best_indexes[1]\n",
    "#             best_indexes[1] = best_indexes[0]\n",
    "#             best_indexes[0] = i\n",
    "#         elif (result[i] > best_results[1]):\n",
    "#             best_results[2] = best_results[1]\n",
    "#             best_results[1] = result[i]\n",
    "#             best_indexes[2] = best_indexes[1]\n",
    "#             best_indexes[1] = i\n",
    "#         elif (result[i] > best_results[2]):\n",
    "#             best_results[2] = result[i]\n",
    "#             best_indexes[2] = i\n",
    "        \n",
    "#     print(classes[best_indexes[0]] + ': ' + str(result[best_indexes[0]] * 100) + '%')\n",
    "#     print(classes[best_indexes[1]] + ': ' + str(result[best_indexes[1]] * 100) + '%')\n",
    "#     print(classes[best_indexes[2]] + ': ' + str(result[best_indexes[2]] * 100) + '%')\n",
    "    \n",
    "#     if (np.where(student['result'] == 1)[0][0] in best_indexes):\n",
    "#         accuracy += 1\n",
    "        \n",
    "#     print()\n",
    "#     print('=================================================')\n",
    "#     print()\n",
    "\n",
    "# print('Точность: ' + str(accuracy / y_real * 100) + '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
